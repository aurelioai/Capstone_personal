{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"color:red;\">The purpose here is to homogenize all data from file 01.</h3>\n",
    "<h4 style=\"color:blue;\">Drop unnecesary data, put labels and whatever is needed with the same names, normalize data...</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>PROJECT TITLE</h1>\n",
    "<h2>Supplementary information (code development)</h2>\n",
    "<h5>By: Aurelio Álvarez Ibarra</h5>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As usual, first we will download and import the necessary packages and libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: beautifulsoup4 in /Users/aurelio/opt/anaconda3/lib/python3.7/site-packages (4.8.2)\n",
      "Requirement already satisfied: lxml in /Users/aurelio/opt/anaconda3/lib/python3.7/site-packages (4.5.0)\n",
      "Requirement already satisfied: soupsieve>=1.2 in /Users/aurelio/opt/anaconda3/lib/python3.7/site-packages (from beautifulsoup4) (1.9.5)\n"
     ]
    }
   ],
   "source": [
    "# Get packages and libraries ready\n",
    "!pip install beautifulsoup4 lxml\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>S1.2 Homogenizing the information from the different sources</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once all source data has been retrieved, the first step to make any analysis is to put all information on the same baseline. Let's read and check the first rows of each dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "USN_df = pd.read_csv('USN_dataframe.csv')\n",
    "QSTU_df = pd.read_csv('QSTopU_dataframe.csv')\n",
    "THE_df = pd.read_csv('THE_dataframe.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's frop unnecesary columns from every dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop unnecesary columns\n",
    "# From USN\n",
    "USN_df.drop(columns=['Unnamed: 0','LatinAmericaRank','City','PageNumber','USN_URL','Webpage'],inplace=True)\n",
    "# From QSTU\n",
    "QSTU_df.drop(columns=['Unnamed: 0','Region',],inplace=True)\n",
    "# From THE\n",
    "THE_df.drop(columns=['Unnamed: 0','RelativeURL'],inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A good idea is to have all data in similar order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Desired order:\n",
    "# University, country, global score, rank, secondary scores, hard data (e.g. number of students), location.\n",
    "USN_df.columns\n",
    "tmpdf = USN_df[['University', 'Country', 'GlobalScore', 'GlobalRank',\n",
    "       'Total number of students', 'Number of international students',\n",
    "       'Total number of academic staff', 'Number of international staff',\n",
    "       'Number of undergraduate degrees awarded',\n",
    "       'Number of master\\'s degrees awarded',\n",
    "       'Number of doctoral degrees awarded', 'Number of research only staff',\n",
    "       'Number of new undergraduate students',\n",
    "       'Number of new master\\'s students', 'Number of new doctoral students', 'Address']]\n",
    "USN_df = tmpdf.copy()\n",
    "del tmpdf\n",
    "# QSTU_df is in the desired order. It does not have hard data.\n",
    "# THE_df is in the desired order."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's shorten and homogenize column labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "USN_df.rename(columns={\"Total number of students\": \"Total_students\",\n",
    "                        \"Number of international students\":\"International_students\",\n",
    "                        \"Total number of academic staff\":\"Academic_staff\",\n",
    "                        \"Number of international staff\":\"International_staff\",\n",
    "                        \"Number of undergraduate degrees awarded\":\"Undergrad_degrees\",\n",
    "                        \"Number of master's degrees awarded\":\"Masters_degrees\",\n",
    "                        \"Number of doctoral degrees awarded\":\"PhDs_degrees\",\n",
    "                        \"Number of research only staff\":\"Research-only_staff\",\n",
    "                        \"Number of new undergraduate students\":\"New_undergrad_students\",\n",
    "                        \"Number of new master's students\":\"New_masters_students\",\n",
    "                        \"Number of new doctoral students\":\"New_PhD_students\"},\n",
    "                        inplace=True)\n",
    "###\n",
    "QSTU_df.rename(columns={'Name': 'University',\n",
    "                        \"International_Students\":\"International_students\",\n",
    "                        \"International_Faculty\":\"International_staff\"},\n",
    "                        inplace=True)\n",
    "###\n",
    "THE_df.rename(columns={\"Name\": \"University\",\n",
    "                       \"Students\":\"Total_students\"},\n",
    "                       inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>University</th>\n",
       "      <th>Country</th>\n",
       "      <th>GlobalScore</th>\n",
       "      <th>GlobalRank</th>\n",
       "      <th>Total_students</th>\n",
       "      <th>International_students</th>\n",
       "      <th>Academic_staff</th>\n",
       "      <th>International_staff</th>\n",
       "      <th>Undergrad_degrees</th>\n",
       "      <th>Masters_degrees</th>\n",
       "      <th>PhDs_degrees</th>\n",
       "      <th>Research-only_staff</th>\n",
       "      <th>New_undergrad_students</th>\n",
       "      <th>New_masters_students</th>\n",
       "      <th>New_PhD_students</th>\n",
       "      <th>Address</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Universidade de São Paulo</td>\n",
       "      <td>Brazil</td>\n",
       "      <td>66.4</td>\n",
       "      <td>128</td>\n",
       "      <td>83,214</td>\n",
       "      <td>3,161</td>\n",
       "      <td>5,230</td>\n",
       "      <td>258.0</td>\n",
       "      <td>8,207</td>\n",
       "      <td>3,742</td>\n",
       "      <td>3,078</td>\n",
       "      <td>0</td>\n",
       "      <td>10,978</td>\n",
       "      <td>4,697</td>\n",
       "      <td>3,308</td>\n",
       "      <td>Av. Prof. Almeida Prado, nº1280 - Butantã São ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  University Country  GlobalScore  GlobalRank Total_students  \\\n",
       "0  Universidade de São Paulo  Brazil         66.4         128         83,214   \n",
       "\n",
       "  International_students Academic_staff  International_staff  \\\n",
       "0                  3,161          5,230                258.0   \n",
       "\n",
       "  Undergrad_degrees Masters_degrees PhDs_degrees Research-only_staff  \\\n",
       "0             8,207           3,742        3,078                   0   \n",
       "\n",
       "  New_undergrad_students New_masters_students New_PhD_students  \\\n",
       "0                 10,978                4,697            3,308   \n",
       "\n",
       "                                             Address  \n",
       "0  Av. Prof. Almeida Prado, nº1280 - Butantã São ...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>University</th>\n",
       "      <th>Country</th>\n",
       "      <th>GlobalScore</th>\n",
       "      <th>GlobalRank</th>\n",
       "      <th>Citations_per_Faculty</th>\n",
       "      <th>International_students</th>\n",
       "      <th>International_staff</th>\n",
       "      <th>Faculty_Student</th>\n",
       "      <th>Employer_Reputation</th>\n",
       "      <th>Academic_Reputation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Universidad de Buenos Aires (UBA)</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>66.0</td>\n",
       "      <td>74</td>\n",
       "      <td>2.4</td>\n",
       "      <td>64.7</td>\n",
       "      <td>50.7</td>\n",
       "      <td>77.4</td>\n",
       "      <td>91.3</td>\n",
       "      <td>87.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          University    Country  GlobalScore  GlobalRank  \\\n",
       "0  Universidad de Buenos Aires (UBA)  Argentina         66.0          74   \n",
       "\n",
       "   Citations_per_Faculty  International_students  International_staff  \\\n",
       "0                    2.4                    64.7                 50.7   \n",
       "\n",
       "   Faculty_Student  Employer_Reputation  Academic_Reputation  \n",
       "0             77.4                 91.3                 87.2  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>University</th>\n",
       "      <th>Country</th>\n",
       "      <th>GlobalScore</th>\n",
       "      <th>GlobalRank</th>\n",
       "      <th>Teaching_score</th>\n",
       "      <th>Research_score</th>\n",
       "      <th>Citations_score</th>\n",
       "      <th>Indust_income_score</th>\n",
       "      <th>Intl_outlook_score</th>\n",
       "      <th>Total_students</th>\n",
       "      <th>Students_per_staff</th>\n",
       "      <th>%_intl_students</th>\n",
       "      <th>Females:males</th>\n",
       "      <th>Address</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>University of Desarrollo</td>\n",
       "      <td>Chile</td>\n",
       "      <td>38.8–42.3</td>\n",
       "      <td>401</td>\n",
       "      <td>13.5</td>\n",
       "      <td>8.8</td>\n",
       "      <td>99.1</td>\n",
       "      <td>36.8</td>\n",
       "      <td>48.1</td>\n",
       "      <td>15,384</td>\n",
       "      <td>19.0</td>\n",
       "      <td>4%</td>\n",
       "      <td>56 : 44</td>\n",
       "      <td>Av. Plaza 680 San Carlos de Apoquindo, Las Con...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 University Country GlobalScore  GlobalRank  Teaching_score  \\\n",
       "0  University of Desarrollo   Chile   38.8–42.3         401            13.5   \n",
       "\n",
       "   Research_score  Citations_score  Indust_income_score  Intl_outlook_score  \\\n",
       "0             8.8             99.1                 36.8                48.1   \n",
       "\n",
       "  Total_students  Students_per_staff %_intl_students Females:males  \\\n",
       "0         15,384                19.0              4%       56 : 44   \n",
       "\n",
       "                                             Address  \n",
       "0  Av. Plaza 680 San Carlos de Apoquindo, Las Con...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(USN_df.head(1))\n",
    "display(QSTU_df.head(1))\n",
    "display(THE_df.head(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr></hr><hr></hr><hr></hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr></hr><hr></hr><hr></hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr></hr><hr></hr><hr></hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr></hr><hr></hr><hr></hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>0.2 Getting coordinates for the neighborhoods from Problem 2</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert file to dataframe\n",
    "toronto_df = pd.read_csv('toronto_data.csv')\n",
    "# Changing the name of the first column of downloaded data\n",
    "toronto_df.rename(columns={'Postal Code':'PostalCode'},inplace=True)\n",
    "# Merging provided data into the original dataframe\n",
    "# dataframe is the original data retrieved and cleaned from wikipedia\n",
    "# toronto_df is the downloaded data\n",
    "full_df = pd.merge(dataframe, toronto_df, on='PostalCode')\n",
    "full_df.drop_duplicates(inplace=True) # Dropping duplicated rows\n",
    "print('Shape of merged dataframe: ',merged.shape)\n",
    "full_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>1.1 Analyzing neighborhoods in Toronto</h4>\n",
    "The purpose of the following code is to group (cluster) different neighborhoods from Toronto in order to see how similar are some of them, and which type of facilities (venues) they have. Maybe you would like to visit neighborhoods with coffee shops and bars one day, and visit neighborhoods with malls and beauty shops another day!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get required packages and libraries ready\n",
    "\n",
    "import numpy as np # library to handle data in a vectorized manner\n",
    "\n",
    "# import pandas as pd # library for data analsysis\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "import json # library to handle JSON files\n",
    "\n",
    "!conda install -c conda-forge geopy --yes\n",
    "from geopy.geocoders import Nominatim # convert an address into latitude and longitude values\n",
    "\n",
    "# import requests # library to handle requests\n",
    "from pandas.io.json import json_normalize # tranform JSON file into a pandas dataframe\n",
    "\n",
    "# Matplotlib and associated plotting modules\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.colors as colors\n",
    "\n",
    "# import k-means from clustering stage\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "!conda install -c conda-forge folium=0.5.0 --yes\n",
    "import folium # map rendering library\n",
    "\n",
    "print('Libraries imported.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>1.2 A first look on Toronto</h4>\n",
    "Let's get some characteristics of the dataframe we have, as well as the location of Toronto in a map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many boroughs and neighborhoods does Toronto have?\n",
    "print('The dataframe \"full_df\" for Toronto has {} boroughs and {} neighborhoods.'\n",
    "      .format(len(full_df['Borough'].unique()),\n",
    "              full_df.shape[0]\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Where is Toronto?\n",
    "address = 'Toronto, Ontario'\n",
    "\n",
    "geolocator = Nominatim(user_agent=\"TO_explorer\")\n",
    "location = geolocator.geocode(address)\n",
    "latitude = location.latitude\n",
    "longitude = location.longitude\n",
    "print('The geographical coordinates of Toronto are {}, {}.'.format(latitude, longitude))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create map of Toronto using its latitude and longitude values\n",
    "map_toronto = folium.Map(location=[latitude, longitude], zoom_start=10)\n",
    "\n",
    "# Add markers of neighborhoods to map\n",
    "for lat, lng, borough, neighborhood, pcode in zip(full_df['Latitude'], full_df['Longitude'],\n",
    "                                                  full_df['Borough'], full_df['Neighborhood'],\n",
    "                                                  full_df['PostalCode']):\n",
    "    label = '{} ({}) {}'.format(neighborhood, borough, pcode)\n",
    "    label = folium.Popup(label, parse_html=True)\n",
    "    folium.CircleMarker(\n",
    "        [lat, lng],\n",
    "        radius=5,\n",
    "        popup=label,\n",
    "        color='blue',\n",
    "        fill=True,\n",
    "        fill_color='#3186cc',\n",
    "        fill_opacity=0.7,\n",
    "        parse_html=False).add_to(map_toronto) # Do not forget to add CircleMarker to the map!!  \n",
    "    \n",
    "map_toronto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to simplify the analysis, the exercise suggests to perform it only in boroughs that include 'Toronto' in its name. Let's extract that information:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the dataframe by appending the desired boroughs\n",
    "tmp = []\n",
    "for i,x in enumerate(full_df['Borough']): # Create an enumerated list of boroughs\n",
    "    if 'Toronto' in x: # Check if Toronto appears in the borough's name\n",
    "        tmp.append(full_df.iloc[i])\n",
    "\n",
    "justtoronto_df = pd.DataFrame(tmp).reset_index(drop=True) # Transform result to dataframe\n",
    "print('Shape of dataframe for Toronto boroughs: ',justtoronto_df.shape)\n",
    "justtoronto_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's adapt the map to the Toronto zone:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just changed \"full_df\" to \"justtoronto_df\"\n",
    "# And I will overwrite the previous map\n",
    "# Create map of Toronto using its latitude and longitude values\n",
    "map_toronto = folium.Map(location=[latitude, longitude], zoom_start=11) # Larger zoom\n",
    "\n",
    "# Add markers of neighborhoods to map\n",
    "for lat, lng, borough, neighborhood, pcode in zip(justtoronto_df['Latitude'], justtoronto_df['Longitude'],\n",
    "                                                  justtoronto_df['Borough'], justtoronto_df['Neighborhood'],\n",
    "                                                  justtoronto_df['PostalCode']):\n",
    "    label = '{} ({}) {}'.format(neighborhood, borough, pcode)\n",
    "    label = folium.Popup(label, parse_html=True)\n",
    "    folium.CircleMarker(\n",
    "        [lat, lng],\n",
    "        radius=5,\n",
    "        popup=label,\n",
    "        color='blue',\n",
    "        fill=True,\n",
    "        fill_color='#3186cc',\n",
    "        fill_opacity=0.7,\n",
    "        parse_html=False).add_to(map_toronto) # Do not forget to add CircleMarker to the map!!  \n",
    "    \n",
    "map_toronto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>2.1 Setting up Foursquare credentials</h4>\n",
    "Please don't eat up my calls credit! XD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLIENT_ID = 'RRYOHBWLN3VNML1RBPM0TRVDW2R41TKNWMZSH0VTOQKGNO2T' # your Foursquare ID\n",
    "CLIENT_SECRET = 'X22FCK21ZCS0UVXZ11TILJFRGXGWVMD5ZADQLIOSMDHHSHHN' # your Foursquare Secret\n",
    "VERSION = '20180605' # Foursquare API version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>2.2 Exploring one neighborhood</h4>\n",
    "In order to make things clear, let's establish the analysis plan using just one neighborhood. Choose by setting a number between 0 and 38 in the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up neighborhood to be analyzed\n",
    "nnum = 5\n",
    "\n",
    "myneigh = justtoronto_df.loc[nnum, 'Neighborhood']\n",
    "myneigh_lat = justtoronto_df.loc[nnum, 'Latitude'] # neighborhood latitude value\n",
    "myneigh_lon = justtoronto_df.loc[nnum, 'Longitude'] # neighborhood longitude value\n",
    "\n",
    "print('Your selected neighborhood is {}, located at (latitude,longitude) = ({},{}).'\n",
    "      .format(myneigh, myneigh_lat, myneigh_lon))\n",
    "print('Don\\'t forget to update this cell when you want to analyze other neighborhood!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code requests the top 100 venues in 500 meters around the location of your neighborhood:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LIMIT=100 # Remember the number and type of calls you have in your credit\n",
    "radius=500 # in meters\n",
    "# The URL structure is straighforward to read.\n",
    "# Just remember the information you have to provide for each type of request.\n",
    "url = 'https://api.foursquare.com/v2/venues/explore?&client_id={}&client_secret={}&v={}&ll={},{}&radius={}&limit={}'.format(\n",
    "           CLIENT_ID,\n",
    "           CLIENT_SECRET,\n",
    "           VERSION,\n",
    "           myneigh_lat,\n",
    "           myneigh_lon,\n",
    "           radius,\n",
    "           LIMIT)\n",
    "url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call to Foursquare. Do not abuse of this cell execution!!!\n",
    "results = requests.get(url).json()\n",
    "### results # Careful. Long result ahead. Uncomment just to be sure that it worked"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the information is in the <i>items</i> key. The following function <code>get_category_type</code> is used to extract the name of a category (remember the structure of the information in the <code>json</code> files)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that extracts the category of the venue\n",
    "def get_category_type(row):\n",
    "    try:\n",
    "        categories_list = row['categories']\n",
    "    except:\n",
    "        categories_list = row['venue.categories']\n",
    "        \n",
    "    if len(categories_list) == 0:\n",
    "        return None\n",
    "    else:\n",
    "        return categories_list[0]['name']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The previous function helps to clean the data from the request:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting \"items\" to work with a smaller amount of data\n",
    "venues = results['response']['groups'][0]['items']\n",
    "\n",
    "# Convert JSON-style data into a table\n",
    "nearby_venues = json_normalize(venues)\n",
    "\n",
    "# Getting only the columns we will use\n",
    "# The names come by looking at the json_normalize result\n",
    "filtered_columns = ['venue.name', 'venue.categories', 'venue.location.lat', 'venue.location.lng']\n",
    "nearby_venues = nearby_venues.loc[:, filtered_columns] # All rows, only the filtered columns\n",
    "\n",
    "# venue.categories looks messy from the previous result. This is why you apply \"get_category_type\"\n",
    "#   to that column, then you get the cleaned name. Of course, the function's design comes after\n",
    "#   checking the data structure in \"venues\".\n",
    "nearby_venues['venue.categories'] = nearby_venues.apply(get_category_type, axis=1)\n",
    "\n",
    "# Remove the \"venues.\" string from the column names\n",
    "nearby_venues.columns = [col.split(\".\")[-1] for col in nearby_venues.columns]\n",
    "\n",
    "# Check the result\n",
    "print('{} venues were returned by Foursquare in {}.'.format(nearby_venues.shape[0],myneigh))\n",
    "nearby_venues.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>3.1 Exploring the full zone</h4>\n",
    "Now that it has been done for one neighborhood, it can be taken to explore the full set of neghborhoods in the selected region of Toronto."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function will do the previous steps with a list of neighborhoods, provided the names and coordinates for each one (and maybe the radius to look for around the location and the limit of venues to search)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getNearbyVenues(names, latitudes, longitudes, radius=500, LIMIT=100):\n",
    "    \n",
    "    venues_list=[]\n",
    "    for name, lat, lng in zip(names, latitudes, longitudes):\n",
    "        print('Searching for venues in ',name,'...')\n",
    "            \n",
    "        # Create URL for API request\n",
    "        url = 'https://api.foursquare.com/v2/venues/explore?&client_id={}&client_secret={}&v={}&ll={},{}&radius={}&limit={}'.format(\n",
    "            CLIENT_ID, \n",
    "            CLIENT_SECRET, \n",
    "            VERSION, \n",
    "            lat, \n",
    "            lng, \n",
    "            radius, \n",
    "            LIMIT)\n",
    "            \n",
    "        # Make GET request, directly retrieving only the interesting part\n",
    "        results = requests.get(url).json()[\"response\"]['groups'][0]['items']\n",
    "        \n",
    "        # Return only relevant information for each nearby venue\n",
    "        venues_list.append([(\n",
    "            name, \n",
    "            lat, \n",
    "            lng, \n",
    "            v['venue']['name'], \n",
    "            v['venue']['location']['lat'], \n",
    "            v['venue']['location']['lng'],  \n",
    "            v['venue']['categories'][0]['name']) for v in results]) # This is a \"list comprehension\"\n",
    "        # In this type of list, you include an implicit for, which can be useful to reduce the number of lines\n",
    "        #   in a code. In this case, it looks in the \"results\" data for the specific elements and values of the\n",
    "        #   previously defined lists.\n",
    "\n",
    "    # Transform result in dataframe\n",
    "    nearby_venues = pd.DataFrame([item for venue_list in venues_list for item in venue_list]) # Nested list comprehension\n",
    "    nearby_venues.columns = ['Neighborhood', \n",
    "                  'Neighborhood Latitude', \n",
    "                  'Neighborhood Longitude', \n",
    "                  'Venue', \n",
    "                  'Venue Latitude', \n",
    "                  'Venue Longitude', \n",
    "                  'Venue Category']\n",
    "    \n",
    "    print()\n",
    "    print('Done!!',end='\\n\\n')\n",
    "    print('Returned a dataframe with shape ',nearby_venues.shape)\n",
    "    return(nearby_venues)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, apply the function to the full set of neighborhoods in Toronto:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toronto_venues = getNearbyVenues(names=justtoronto_df['Neighborhood'],\n",
    "                                   latitudes=justtoronto_df['Latitude'],\n",
    "                                   longitudes=justtoronto_df['Longitude']\n",
    "                                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toronto_venues.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many venues does each neighborhood has?\n",
    "print('Number of venues retrieved per neighborhood (dataframe):')\n",
    "toronto_venues.groupby('Neighborhood').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that the number of venues returned by Foursquare here matches the one in your \"one neighborhood\" analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many type of venues are there in this dataframe?\n",
    "print('There are {} uniques categories of venues in the dataframe.'.format(len(toronto_venues['Venue Category'].unique())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>3.2 Managing the information</h4>\n",
    "The following code will create a dataframe that show how many venues of a given type exists in each neighborhood. The dataframe will be large but this is the preparation step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One hot encoding\n",
    "# Create a dummy dataframe with columns after (unique) values in 'Venue Category'\n",
    "toronto_onehot = pd.get_dummies(toronto_venues[['Venue Category']], prefix=\"\", prefix_sep=\"\")\n",
    "\n",
    "# Add neighborhood column back to dataframe\n",
    "# With this you just create a 'Neighborhood' column in toronto_onehot\n",
    "#   with the info from toronto_venues['Neighborhood']\n",
    "toronto_onehot['Neighborhood'] = toronto_venues['Neighborhood'] \n",
    "\n",
    "# Move neighborhood column to the first column\n",
    "# The previous code results in an alphabetical order in the columns (left-to-right)\n",
    "#   thus let's move the 'Neighborhood' column to the beginning.\n",
    "colind = toronto_onehot.columns.get_loc(\"Neighborhood\") # Getting the position of column in dataframe\n",
    "fixed_columns = [toronto_onehot.columns[colind]] + list(toronto_onehot.columns[0:colind]) + list(toronto_onehot.columns[colind+1:])\n",
    "toronto_onehot = toronto_onehot[fixed_columns]\n",
    "\n",
    "### Warning! In the lab exercise, the 'Neighborhood' column was added at the end of\n",
    "###   the dataframe. That is why there you see a '-1' index to refer to that column.\n",
    "###       fixed_columns = [toronto_onehot.columns[-1]] + list(toronto_onehot.columns[:-1])\n",
    "###       toronto_onehot = toronto_onehot[fixed_columns]\n",
    "###   While checking here, I realized the alphabetical order (don't know why!).\n",
    "###   Thus, I had to modify the code to look for the column by name.\n",
    "\n",
    "toronto_onehot.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The previous dataframe establishes the occurrence of a given venue in a particular neighborhood. Let's group the occurrence of each type (category) of venue per neighborhood, making a <code>mean</code> out of the location to have an idea of the frequency of such occurrence per neighborhood. This is, of the total of venues in a given neighborhood, how feasible is to find a given type of venue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toronto_grouped = toronto_onehot.groupby('Neighborhood').mean().reset_index()\n",
    "toronto_grouped.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see in the previous results, it is more feasible to find a coffee shop than an art gallery in Berczy Park. This is more easily seen if you print the top 5 venues (according to frequency) for each neighborhood."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_top_venues = 5\n",
    "\n",
    "for hood in toronto_grouped['Neighborhood']:\n",
    "    print(\"----\" + hood + \"----\") # \"plus\" signs do not work if you mix strings and numbers!\n",
    "    # T is for Transposed. It gets the venue categories to the index side.\n",
    "    temp = toronto_grouped[toronto_grouped['Neighborhood'] == hood].T.reset_index()\n",
    "    temp.columns = ['venue','freq']\n",
    "    temp = temp.iloc[1:]\n",
    "    temp['freq'] = temp['freq'].astype(float)\n",
    "    temp = temp.round({'freq': 3})\n",
    "    print(temp.sort_values('freq', ascending=False).reset_index(drop=True).head(num_top_venues))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Note</b>: Remember that this <i>frequency</i> analysis depends on the number of venues in the neighborhood. If you see very small numbers in the top 5, it may mean there is a lot of venues in the neighborhood."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get this information into a dataframe, it is easier to create a function to return the top venues in a . The next cell will create the dataframe in a readable way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_most_common_venues(row, num_top_venues):\n",
    "    row_categories = row.iloc[1:]\n",
    "    row_categories_sorted = row_categories.sort_values(ascending=False)\n",
    "    \n",
    "    return row_categories_sorted.index.values[0:num_top_venues]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_top_venues = 10\n",
    "\n",
    "indicators = ['st', 'nd', 'rd'] # Not needed if you use \"Venue #X\" for X = 1 to num_top_venues\n",
    "\n",
    "# Create columns according to number of top venues\n",
    "columns = ['Neighborhood']\n",
    "for ind in np.arange(num_top_venues):\n",
    "    try:\n",
    "        columns.append('{}{} Most Common Venue'.format(ind+1, indicators[ind])) # Indicators for 1, 2 and 3\n",
    "    except:\n",
    "        columns.append('{}th Most Common Venue'.format(ind+1)) # When you run out of \"indicators\"\n",
    "\n",
    "# Create a new dataframe\n",
    "neighborhoods_venues_sorted = pd.DataFrame(columns=columns) # As wide as num_top_venues + 1\n",
    "neighborhoods_venues_sorted['Neighborhood'] = toronto_grouped['Neighborhood'] # Copy neighborhoods from dataframe\n",
    "\n",
    "for ind in np.arange(toronto_grouped.shape[0]): # For the number of neighborhoods in the dataframe...\n",
    "    # The function returns the first \"num_top_venues\" from the ordered list from each row\n",
    "    neighborhoods_venues_sorted.iloc[ind, 1:] = return_most_common_venues(toronto_grouped.iloc[ind, :], num_top_venues)\n",
    "\n",
    "neighborhoods_venues_sorted.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>4.1 Clustering neighborhoods using <i>K means</i></h4>\n",
    "The following code runs the <code>K means</code> model on several values for number of clusters and random-number-generator seeds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toronto_grouped_clustering = toronto_grouped.drop('Neighborhood', 1)\n",
    "for kclusters in range(3,6):\n",
    "    print()\n",
    "    print('Results for K-means with k = ',kclusters)\n",
    "    for seed in range(0,5):\n",
    "        # Execute k-means clustering for given conditions\n",
    "        kmeans = KMeans(n_clusters=kclusters, random_state=seed, n_init=12).fit(toronto_grouped_clustering)    \n",
    "        # Check cluster labels generated for each row in the dataframe\n",
    "        print('For k = {} and seed = {} the labels are: \\n {}'.format(kclusters,seed,kmeans.labels_[0:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The value of the <code>seed</code> for the random number generator that initializes the centroids of the clusters seems to influence more for lower <code>kcluster</code> values. With <code>kclusters=5</code> the results are the same. Let's use those values for the clustering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toronto_grouped_clustering = toronto_grouped.drop('Neighborhood', 1)\n",
    "kmeans = KMeans(n_clusters=5, random_state=0, n_init=12).fit(toronto_grouped_clustering)\n",
    "kmeans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's complete the dataframe for Toronto neighborhoods with the data from the neighborhoods, cluster label and top venues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add clustering labels to the sorted neighborhood venues\n",
    "neighborhoods_venues_sorted.insert(0, 'Cluster Labels', kmeans.labels_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recover the original dataframe (in this case, \"justtoronto_df\")\n",
    "toronto_merged = justtoronto_df\n",
    "\n",
    "# Add neighborhoods_venues_sorted to toronto_merged according to the neighborhood name\n",
    "toronto_merged = toronto_merged.join(neighborhoods_venues_sorted.set_index('Neighborhood'), on='Neighborhood')\n",
    "\n",
    "toronto_merged.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the final presentation, a map with colored markers for each cluster is shown as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting Toronto's coordinates\n",
    "address = 'Toronto, Ontario'\n",
    "geolocator = Nominatim(user_agent=\"TO_explorer\")\n",
    "location = geolocator.geocode(address)\n",
    "latitude = location.latitude\n",
    "longitude = location.longitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create map object\n",
    "map_clusters = folium.Map(location=[latitude, longitude], zoom_start=11)\n",
    "\n",
    "# Set color scheme for each cluster\n",
    "x = np.arange(kclusters)\n",
    "ys = [i + x + (i*x)**2 for i in range(kclusters)]\n",
    "colors_array = cm.gnuplot(np.linspace(0, 1, len(ys))) # Look for color maps in matplotlib\n",
    "rainbow = [colors.rgb2hex(i) for i in colors_array]\n",
    "\n",
    "# Add markers to the map\n",
    "markers_colors = []\n",
    "for lat, lon, hood, cluster in zip(toronto_merged['Latitude'], toronto_merged['Longitude'],\n",
    "                                  toronto_merged['Neighborhood'], toronto_merged['Cluster Labels']):\n",
    "    label = folium.Popup(str(hood) + ' (in Cluster ' + str(cluster) + ')', parse_html=True)\n",
    "    folium.CircleMarker(\n",
    "        [lat, lon],\n",
    "        radius=5,\n",
    "        popup=label,\n",
    "        color=rainbow[cluster-1],\n",
    "        fill=True,\n",
    "        fill_color=rainbow[cluster-1],\n",
    "        fill_opacity=0.7).add_to(map_clusters)\n",
    "       \n",
    "map_clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>4.2 Examining clusters</h4>\n",
    "Why that many neighborhoods are in a specific cluster? Let's see the top venues in each cluster and compare between them. Since cluster 3 is the more populated, let's check that one first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mycluster = 0\n",
    "toronto_merged.loc[toronto_merged['Cluster Labels'] == mycluster, toronto_merged.columns[[2] + list(range(5, toronto_merged.shape[1]))]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>NOTE</b>: If you run this notebook again, the \"big\" cluster can get another label. In this example, it came to be 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For cluster 0, coffee shops and cafés are the common venues on the top list. What happens with neighborhoods like \"Dufferin, Dovercourt Village\" (index 9)? It does not seem very similar. It shares bakery and bar on his top venues with a couple of other neighborhoods but it seems rather odd. Maybe the analysis tends to load the separation on the top venues rather than the whole set. Anyway, remember we are looking at the top venues here, not at every one of them. For the rest of the clusters, the comparison is straightforward:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mycluster = 1\n",
    "toronto_merged.loc[toronto_merged['Cluster Labels'] == mycluster, toronto_merged.columns[[2] + list(range(5, toronto_merged.shape[1]))]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mycluster = 2\n",
    "toronto_merged.loc[toronto_merged['Cluster Labels'] == mycluster, toronto_merged.columns[[2] + list(range(5, toronto_merged.shape[1]))]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mycluster = 3\n",
    "toronto_merged.loc[toronto_merged['Cluster Labels'] == mycluster, toronto_merged.columns[[2] + list(range(5, toronto_merged.shape[1]))]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mycluster = 4\n",
    "toronto_merged.loc[toronto_merged['Cluster Labels'] == mycluster, toronto_merged.columns[[2] + list(range(5, toronto_merged.shape[1]))]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the clusters with more than one element, top venues are very similar. There, the clustering makes sense. It may be a challenge to further analyze the data in order to see why the clustering puts that many neighborhoods in one of them (remember the results for <code>kclusters</code> from 3 to 4 in the beginning of section 4.1). Some straightforward ideas on this can be found <a href=\"https://zerowithdot.com/mistakes-with-k-means-clustering/\">here</a> and some solutions are suggested <a href=\"https://www.datanovia.com/en/lessons/determining-the-optimal-number-of-clusters-3-must-know-methods/\">here</a>. Since this is a high-dimensionality problem, the suggestion I have is to try several clusters and check the label distribution. Just set <code>maxclusters</code> in the following cell and see what's a good candidate! After that, rinse and repeat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toronto_grouped_clustering = toronto_grouped.drop('Neighborhood', 1)\n",
    "maxclusters = 10\n",
    "seed = 0\n",
    "save_k = 10\n",
    "for kclusters in range(3,maxclusters+1):\n",
    "    print()\n",
    "    print('Results for K-means with k = ',kclusters)\n",
    "    # Execute k-means clustering for given conditions\n",
    "    tmp = KMeans(n_clusters=kclusters, random_state=seed, n_init=12).fit(toronto_grouped_clustering)    \n",
    "    # Check cluster labels generated for each row in the dataframe\n",
    "    print('For k = {} and seed = {} the labels are: \\n {}'.format(kclusters,seed,tmp.labels_[0:]))\n",
    "    if kclusters == save_k:\n",
    "        kmeans = tmp\n",
    "print()\n",
    "print('Saved results for kclusters = ',save_k,' in \"kmeans\"')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
