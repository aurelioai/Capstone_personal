{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"color:red;\">The purpose here is to define the source of university rankings data, then check how to scrap each data and then how to merge the data from different sources.</h3>\n",
    "<h4 style=\"color:blue;\">The plan now is to scrap data from three different sources. This would lead to three different webpages, with three different scrapping algorithms and finally the collection of data. One thing I would like to do is to run a similarity analysis between the sources to see how consistent are between them.</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>PROJECT TITLE</h1>\n",
    "<h2>Supplementary information (code development)</h2>\n",
    "<h5>By: Aurelio Álvarez Ibarra</h5>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>S1.1 Getting information from the ranking tables</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As usual, first we will download and import the necessary packages and libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: beautifulsoup4 in /Users/aurelio/opt/anaconda3/lib/python3.7/site-packages (4.8.2)\n",
      "Requirement already satisfied: lxml in /Users/aurelio/opt/anaconda3/lib/python3.7/site-packages (4.5.0)\n",
      "Requirement already satisfied: soupsieve>=1.2 in /Users/aurelio/opt/anaconda3/lib/python3.7/site-packages (from beautifulsoup4) (1.9.5)\n"
     ]
    }
   ],
   "source": [
    "# Get packages and libraries ready\n",
    "!pip install beautifulsoup4 lxml\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Source one: Times Higher Education</h4>\n",
    "The first source of data will be the ranking by <a href=\"https://www.timeshighereducation.com/world-university-rankings/2020/world-ranking\">Times Higher Education</a>. <b>SAY SOMETHING ABOUT THE SOURCE...</b>. The data will be restricted to some Latin American countries. The ones available in this ranking are:\n",
    "<ul>\n",
    "    <li>Argentina (identified as AR)</li>\n",
    "    <li>Brasil (identified as BR)</li>\n",
    "    <li>Chile (identified as CL)</li>\n",
    "    <li>Colombia (identified as CO)</li>\n",
    "    <li>Costa Rica (identified as CR)</li>\n",
    "    <li>Cuba (identified as CU)</li>\n",
    "    <li>Jamaica (identified as JM)</li>\n",
    "    <li>Mexico (identified as MX)</li>\n",
    "    <li>Peru (identified as PE)</li>\n",
    "    <li>Puerto Rico (identified as PR)</li>\n",
    "    <li>Venezuela (identified as VE)</li>\n",
    "</ul>\n",
    "Let's try this first source with the full list. In the process the structure of the webpage will be studied in order to systematically retrieve the data for every countries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [403]>\n"
     ]
    }
   ],
   "source": [
    "# Save data from webpage\n",
    "myurl = 'https://www.timeshighereducation.com/world-university-rankings/2020/world-ranking#!/page/0/length/-1/locations/AR/sort_by/rank/sort_order/asc/cols/stats'\n",
    "## The structure of the webpage is:\n",
    "##   1.- Main URL and starting page (0):\n",
    "##       https://www.timeshighereducation.com/world-university-rankings/2020/world-ranking#!/page/0/\n",
    "##   2.- Number of results per page (-1 means \"All\"):\n",
    "##       length/-1/\n",
    "##   3.- Location definition (check the country identifier above):\n",
    "##       locations/AR/\n",
    "##   4.- Sorting parameters:\n",
    "##       sort_by/rank/sort_order/asc/\n",
    "##   5.- Information shown (\"stats\"=ranking data; \"scores\"=scoring data):\n",
    "##       cols/stats\n",
    "source = requests.get(myurl)\n",
    "print(source)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The response from the Times Higher Education server is to deny incoming requests from this type (403). Sometimes, webpages require to define a <code>User-Agent</code> as explained <a href=\"https://stackoverflow.com/questions/38489386/python-requests-403-forbidden\">here</a>. On top of that, when retrieving the table section of the webpage, the <code>tbody</code> tag (which encloses the data in the body of the table) is empty. According to this <a href=\"https://stackoverflow.com/questions/49260014/beautifulsoup-returns-empty-td-tags\">source</a>, the table data may be generated by a script and not with the HTML code itself. Thus, extra information must be included in the header and in the <code>requests.get</code> arguments to get the results of such script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save data from webpage\n",
    "myurl = 'https://www.timeshighereducation.com/world-university-rankings/2020/world-ranking#!/page/0/length/-1/sort_by/rank/sort_order/asc/cols/stats'\n",
    "header = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/64.0.3282.186 Safari/537.36','Accept': 'application/json, text/javascript, */*; q=0.01'}\n",
    "source = requests.get(myurl,headers=header).text # Without .text, it gets the response in JSON format\n",
    "mysoup = BeautifulSoup(source,'lxml')\n",
    "mytable = mysoup.find('table')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The previous results in a table object with an emtpy <code>tbody</code> tag as well. Unfortunately, I could not figure out how to get the actual data from the table. I checked many sources but it would be too much for me to understand it right away. I tried with another retriever but got the same result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### My try with urlib.requests... generates the same result (empty tbody)\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib.request\n",
    "\n",
    "url_to_scrape = 'https://www.timeshighereducation.com/world-university-rankings/2020/world-ranking#!/page/0/length/-1/sort_by/rank/sort_order/asc/cols/stats'\n",
    "soup = BeautifulSoup(urllib.request.urlopen(url_to_scrape).read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I decide to drop source one..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Source two: U.S. News</h4>\n",
    "The second source of data will be the ranking by <a href=\"https://www.usnews.com/education/best-global-universities/rankings\">U.S. News</a>. <b>SAY SOMETHING ABOUT THE SOURCE...</b>. The data will be restricted to the Latin American countries in their search results. <br><br>\n",
    "Looking at the structure of the page, the data is not in a table but in a set of <code>div</code> tags with <code>class=\"sep\"</code>. A concerning details is that it is not possible to ask for the full list in one shot (there is no option like \"Show all\" in this source), but this will be solved later. For the first page of results for the Latin American universities, the retrieving code is the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elements in the search result:  10\n"
     ]
    }
   ],
   "source": [
    "# Save data from webpage\n",
    "myurl = 'https://www.usnews.com/education/best-global-universities/search?region=latin-america'\n",
    "#header = {'User-Agent': 'Mozilla/5.0 (Windows NT 6.1; WOW64; rv:50.0) Gecko/20100101 Firefox/50.0'}\n",
    "header = {\"User-Agent\":\"Mozilla/5.0\"}\n",
    "source = requests.get(myurl,headers=header).text # Without .text, it gets the response in JSON format\n",
    "mysoup = BeautifulSoup(source,'lxml')\n",
    "\n",
    "\n",
    "# I need this function to find the div with the specific class\n",
    "mydivs = mysoup.find_all(lambda tag: tag.name == 'div' and\n",
    "                         tag.get('class') == ['sep'])\n",
    "print(\"Elements in the search result: \",len(mydivs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using this method, I get a list as a result. According to its lenght, I know how many elements I shall analyze. For the first ten results in the Latin America ranking, the following data can be retrieved:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** Universidade de São Paulo, #1 in Latin America with a global score of 66.4, is located in São Paulo (Brazil).\n",
      "** Pontificia University Católica de Chile, #2 in Latin America with a global score of 57.2, is located in Santiago (Chile).\n",
      "** State University of Campinas, #3 in Latin America with a global score of 56.7, is located in Campinas, São Paulo (Brazil).\n",
      "** Federal University of Rio de Janeiro, #4 in Latin America with a global score of 54.9, is located in Rio de Janeiro (Brazil).\n",
      "** University of Buenos Aires, #5 in Latin America with a global score of 53.7, is located in Buenos Aires City, Buenos Aires (Argentina).\n",
      "** National Autonomous University of Mexico, #6 in Latin America with a global score of 53.4, is located in Ciudad de México, Distrito Federal (Mexico).\n",
      "** University of Chile, #7 in Latin America with a global score of 53.1, is located in Santiago (Chile).\n",
      "** University of the Andes Colombia, #8 in Latin America with a global score of 51.4, is located in Bogotá, DC (Colombia).\n",
      "** Universidad Tecnica Federico Santa Maria, #9 in Latin America with a global score of 51.1, is located in Valparaiso, Valparaiso (Chile).\n",
      "** Federal University of Rio Grande do Sul, #10 in Latin America with a global score of 50.4, is located in Porto Alegre, Rio Grande do Sul (Brazil).\n"
     ]
    }
   ],
   "source": [
    "import re # For the regex search in the local ranking\n",
    "###\n",
    "ind = 0\n",
    "univnames = []\n",
    "for myUname in mysoup.find_all(\"h2\",class_=\"h-taut\"): # All tags with university name\n",
    "#    print(myUname.text.strip())\n",
    "    univnames.append(myUname.text.strip())\n",
    "    ind = ind+1\n",
    "###\n",
    "ind = 0\n",
    "LAranks = []\n",
    "for myLArank in mysoup.find_all(\"div\",class_=\"thumb-left\"): # All tags with rank in LatinAmerica (see myurl)\n",
    "    # Score comes with a # sign and maybe a TIE string. Convert to number\n",
    "    LAranks.append(int(re.findall(\"[0-9]+\",str(myLArank))[0]))\n",
    "    ind = ind+1\n",
    "###\n",
    "ind = 0\n",
    "globalscores = []\n",
    "for myGscore in mysoup.find_all(\"div\",class_=\"t-large t-strong t-constricted\"): # All tags with global score number\n",
    "    globalscores.append(myGscore.text)\n",
    "    ind = ind+1\n",
    "###\n",
    "ind = 0\n",
    "countries = []\n",
    "cities = []\n",
    "for mylocation in mysoup.find_all(\"div\",class_=\"t-taut\"): # All tags with location\n",
    "    countries.append(mylocation.span.text.strip())\n",
    "    cities.append(mylocation.find(\"span\",class_=\"t-dim t-small\").text.strip())\n",
    "    ind = ind+1\n",
    "###\n",
    "for ind in range(len(mydivs)):\n",
    "    print('** {}, #{} in Latin America with a global score of {}, is located in {} ({}).'.format(univnames[ind],LAranks[ind],globalscores[ind],cities[ind],countries[ind]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the next pages, an extra string appears in the URL: <code>page=#</code>, where <code>#</code> goes from 2 to 10 in this particular case. For <code>#</code>=1, this \"extra\" string does not appear. The following loop retrieves as many pages as stated in <code>numpages</code>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize fields\n",
    "univnames = []\n",
    "LAranks = []\n",
    "globalscores = []\n",
    "countries = []\n",
    "cities = []\n",
    "pagenum = []\n",
    "###\n",
    "\n",
    "# Defining extra strings in URL and setting up request\n",
    "myurl = 'https://www.usnews.com/education/best-global-universities/latin-america'\n",
    "numpages = 10\n",
    "extrastring = ['']\n",
    "for mypages in range(2,numpages+1):\n",
    "    mytext = '?page='\n",
    "    extrastring.append(mytext+str(mypages))\n",
    "header = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko)'\n",
    "          +' Chrome/64.0.3282.186 Safari/537.36','Accept': 'application/json, text/javascript, */*; q=0.01'}\n",
    "header = {\"User-Agent\":\"Mozilla/5.0\"}\n",
    "\n",
    "# Loop for pages 1 to numpages\n",
    "for n in range(1,numpages+1):\n",
    "    url = myurl + extrastring[n-1]\n",
    "    source = requests.get(url,headers=header).text\n",
    "    mysoup = BeautifulSoup(source,'lxml')\n",
    "\n",
    "    ### University names\n",
    "    for myUname in mysoup.find_all(\"h2\",class_=\"h-taut\"): # All tags with university name\n",
    "        univnames.append(myUname.text.strip())\n",
    "    ### University rank (in Latin America)\n",
    "    for myLArank in mysoup.find_all(\"div\",class_=\"thumb-left\"): # All tags with rank in LatinAmerica (see myurl)\n",
    "        try:\n",
    "            LAranks.append(int(re.findall(\"[0-9]+\",str(myLArank))[0]))\n",
    "        except:\n",
    "            LAranks.append(None)\n",
    "    ### University global score\n",
    "    for myGscore in mysoup.find_all(\"div\",class_=\"t-large t-strong t-constricted\"): # All tags with global score number\n",
    "        globalscores.append(myGscore.text.strip())\n",
    "    ### University location (country and city)\n",
    "    for mylocation in mysoup.find_all(\"div\",class_=\"t-taut\"): # All tags with global score\n",
    "        countries.append(mylocation.span.text.strip())\n",
    "        cities.append(mylocation.find(\"span\",class_=\"t-dim t-small\").text.strip())\n",
    "    ### Page number of this batch of data\n",
    "    maxscores = len(mysoup.find_all(\"div\",class_=\"t-large t-strong t-constricted\"))\n",
    "    for mypage in range(1,maxscores+1):\n",
    "        pagenum.append(n)\n",
    "# Universities without global score do not have complete data (see below), thus they will be dropped\n",
    "##for ind in range(len(globalscores)):\n",
    "##    print('** {}, #{} in Latin America with a global score of {}, is located in {} ({}).'.format(univnames[ind],LAranks[ind],globalscores[ind],cities[ind],countries[ind]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's combine all the lists in a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>University</th>\n",
       "      <th>LatinAmericaRank</th>\n",
       "      <th>GlobalScore</th>\n",
       "      <th>Country</th>\n",
       "      <th>City</th>\n",
       "      <th>PageNumber</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Universidade de São Paulo</td>\n",
       "      <td>1</td>\n",
       "      <td>66.4</td>\n",
       "      <td>Brazil</td>\n",
       "      <td>São Paulo</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pontificia University Católica de Chile</td>\n",
       "      <td>2</td>\n",
       "      <td>57.2</td>\n",
       "      <td>Chile</td>\n",
       "      <td>Santiago</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>State University of Campinas</td>\n",
       "      <td>3</td>\n",
       "      <td>56.7</td>\n",
       "      <td>Brazil</td>\n",
       "      <td>Campinas, São Paulo</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Federal University of Rio de Janeiro</td>\n",
       "      <td>4</td>\n",
       "      <td>54.9</td>\n",
       "      <td>Brazil</td>\n",
       "      <td>Rio de Janeiro</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>University of Buenos Aires</td>\n",
       "      <td>5</td>\n",
       "      <td>53.7</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>Buenos Aires City, Buenos Aires</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>National Autonomous University of Mexico</td>\n",
       "      <td>6</td>\n",
       "      <td>53.4</td>\n",
       "      <td>Mexico</td>\n",
       "      <td>Ciudad de México, Distrito Federal</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>University of Chile</td>\n",
       "      <td>7</td>\n",
       "      <td>53.1</td>\n",
       "      <td>Chile</td>\n",
       "      <td>Santiago</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>University of the Andes Colombia</td>\n",
       "      <td>8</td>\n",
       "      <td>51.4</td>\n",
       "      <td>Colombia</td>\n",
       "      <td>Bogotá, DC</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Universidad Tecnica Federico Santa Maria</td>\n",
       "      <td>9</td>\n",
       "      <td>51.1</td>\n",
       "      <td>Chile</td>\n",
       "      <td>Valparaiso, Valparaiso</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Federal University of Rio Grande do Sul</td>\n",
       "      <td>10</td>\n",
       "      <td>50.4</td>\n",
       "      <td>Brazil</td>\n",
       "      <td>Porto Alegre, Rio Grande do Sul</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 University  LatinAmericaRank GlobalScore  \\\n",
       "0                 Universidade de São Paulo                 1        66.4   \n",
       "1   Pontificia University Católica de Chile                 2        57.2   \n",
       "2              State University of Campinas                 3        56.7   \n",
       "3      Federal University of Rio de Janeiro                 4        54.9   \n",
       "4                University of Buenos Aires                 5        53.7   \n",
       "5  National Autonomous University of Mexico                 6        53.4   \n",
       "6                       University of Chile                 7        53.1   \n",
       "7          University of the Andes Colombia                 8        51.4   \n",
       "8  Universidad Tecnica Federico Santa Maria                 9        51.1   \n",
       "9   Federal University of Rio Grande do Sul                10        50.4   \n",
       "\n",
       "     Country                                City  PageNumber  \n",
       "0     Brazil                           São Paulo           1  \n",
       "1      Chile                            Santiago           1  \n",
       "2     Brazil                 Campinas, São Paulo           1  \n",
       "3     Brazil                      Rio de Janeiro           1  \n",
       "4  Argentina     Buenos Aires City, Buenos Aires           1  \n",
       "5     Mexico  Ciudad de México, Distrito Federal           1  \n",
       "6      Chile                            Santiago           1  \n",
       "7   Colombia                          Bogotá, DC           1  \n",
       "8      Chile              Valparaiso, Valparaiso           1  \n",
       "9     Brazil     Porto Alegre, Rio Grande do Sul           1  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import pandas as pd\n",
    "maxlenght = len(globalscores)\n",
    "USN_df=pd.DataFrame({'University':univnames[0:maxlenght],\n",
    "                        'LatinAmericaRank':LAranks[0:maxlenght],\n",
    "                        'GlobalScore':globalscores[0:maxlenght],\n",
    "                        'Country':countries[0:maxlenght],\n",
    "                        'City':cities[0:maxlenght],\n",
    "                        'PageNumber':pagenum[0:maxlenght]}\n",
    "                      )\n",
    "USN_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Details for the university ranking appear when clicking on the university's name. The resulting URL includes a variant of the university and a numeric identifier. This information can be found in an <code>a</code> tag inside the <code>h2</code> tag used to retriege the university name. The previous data retriever will be used to get the URL for each university."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>University</th>\n",
       "      <th>LatinAmericaRank</th>\n",
       "      <th>GlobalScore</th>\n",
       "      <th>Country</th>\n",
       "      <th>City</th>\n",
       "      <th>PageNumber</th>\n",
       "      <th>USN_URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Universidade de São Paulo</td>\n",
       "      <td>1</td>\n",
       "      <td>66.4</td>\n",
       "      <td>Brazil</td>\n",
       "      <td>São Paulo</td>\n",
       "      <td>1</td>\n",
       "      <td>https://www.usnews.com/education/best-global-u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pontificia University Católica de Chile</td>\n",
       "      <td>2</td>\n",
       "      <td>57.2</td>\n",
       "      <td>Chile</td>\n",
       "      <td>Santiago</td>\n",
       "      <td>1</td>\n",
       "      <td>https://www.usnews.com/education/best-global-u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>State University of Campinas</td>\n",
       "      <td>3</td>\n",
       "      <td>56.7</td>\n",
       "      <td>Brazil</td>\n",
       "      <td>Campinas, São Paulo</td>\n",
       "      <td>1</td>\n",
       "      <td>https://www.usnews.com/education/best-global-u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Federal University of Rio de Janeiro</td>\n",
       "      <td>4</td>\n",
       "      <td>54.9</td>\n",
       "      <td>Brazil</td>\n",
       "      <td>Rio de Janeiro</td>\n",
       "      <td>1</td>\n",
       "      <td>https://www.usnews.com/education/best-global-u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>University of Buenos Aires</td>\n",
       "      <td>5</td>\n",
       "      <td>53.7</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>Buenos Aires City, Buenos Aires</td>\n",
       "      <td>1</td>\n",
       "      <td>https://www.usnews.com/education/best-global-u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>Universidade Tecnologica Federal do Parana</td>\n",
       "      <td>79</td>\n",
       "      <td>16.5</td>\n",
       "      <td>Brazil</td>\n",
       "      <td>Curitiba</td>\n",
       "      <td>8</td>\n",
       "      <td>https://www.usnews.com/education/best-global-u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>Universidade Federal de Sergipe</td>\n",
       "      <td>80</td>\n",
       "      <td>16.3</td>\n",
       "      <td>Brazil</td>\n",
       "      <td>São Cristóvão</td>\n",
       "      <td>8</td>\n",
       "      <td>https://www.usnews.com/education/best-global-u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>Universidade Federal Rural de Pernambuco (UFRPE)</td>\n",
       "      <td>81</td>\n",
       "      <td>15.9</td>\n",
       "      <td>Brazil</td>\n",
       "      <td>Recife, PE</td>\n",
       "      <td>9</td>\n",
       "      <td>https://www.usnews.com/education/best-global-u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>Universidad Autonoma de Baja California</td>\n",
       "      <td>82</td>\n",
       "      <td>15.6</td>\n",
       "      <td>Mexico</td>\n",
       "      <td>Mexicali, Baja California</td>\n",
       "      <td>9</td>\n",
       "      <td>https://www.usnews.com/education/best-global-u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>Universidad Veracruzana</td>\n",
       "      <td>82</td>\n",
       "      <td>15.6</td>\n",
       "      <td>Mexico</td>\n",
       "      <td>Xalapa, Veracruz</td>\n",
       "      <td>9</td>\n",
       "      <td>https://www.usnews.com/education/best-global-u...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>83 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          University  LatinAmericaRank  \\\n",
       "0                          Universidade de São Paulo                 1   \n",
       "1            Pontificia University Católica de Chile                 2   \n",
       "2                       State University of Campinas                 3   \n",
       "3               Federal University of Rio de Janeiro                 4   \n",
       "4                         University of Buenos Aires                 5   \n",
       "..                                               ...               ...   \n",
       "78        Universidade Tecnologica Federal do Parana                79   \n",
       "79                   Universidade Federal de Sergipe                80   \n",
       "80  Universidade Federal Rural de Pernambuco (UFRPE)                81   \n",
       "81           Universidad Autonoma de Baja California                82   \n",
       "82                           Universidad Veracruzana                82   \n",
       "\n",
       "   GlobalScore    Country                             City  PageNumber  \\\n",
       "0         66.4     Brazil                        São Paulo           1   \n",
       "1         57.2      Chile                         Santiago           1   \n",
       "2         56.7     Brazil              Campinas, São Paulo           1   \n",
       "3         54.9     Brazil                   Rio de Janeiro           1   \n",
       "4         53.7  Argentina  Buenos Aires City, Buenos Aires           1   \n",
       "..         ...        ...                              ...         ...   \n",
       "78        16.5     Brazil                         Curitiba           8   \n",
       "79        16.3     Brazil                    São Cristóvão           8   \n",
       "80        15.9     Brazil                       Recife, PE           9   \n",
       "81        15.6     Mexico        Mexicali, Baja California           9   \n",
       "82        15.6     Mexico                 Xalapa, Veracruz           9   \n",
       "\n",
       "                                              USN_URL  \n",
       "0   https://www.usnews.com/education/best-global-u...  \n",
       "1   https://www.usnews.com/education/best-global-u...  \n",
       "2   https://www.usnews.com/education/best-global-u...  \n",
       "3   https://www.usnews.com/education/best-global-u...  \n",
       "4   https://www.usnews.com/education/best-global-u...  \n",
       "..                                                ...  \n",
       "78  https://www.usnews.com/education/best-global-u...  \n",
       "79  https://www.usnews.com/education/best-global-u...  \n",
       "80  https://www.usnews.com/education/best-global-u...  \n",
       "81  https://www.usnews.com/education/best-global-u...  \n",
       "82  https://www.usnews.com/education/best-global-u...  \n",
       "\n",
       "[83 rows x 7 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize fields\n",
    "univurl = []\n",
    "\n",
    "# Defining extra strings in URL and setting up request\n",
    "myurl = 'https://www.usnews.com/education/best-global-universities/latin-america'\n",
    "numpages = 10\n",
    "extrastring = ['']\n",
    "for mypages in range(2,numpages+1):\n",
    "    mytext = '?page='\n",
    "    extrastring.append(mytext+str(mypages))\n",
    "header = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko)'\n",
    "          +' Chrome/64.0.3282.186 Safari/537.36','Accept': 'application/json, text/javascript, */*; q=0.01'}\n",
    "header = {\"User-Agent\":\"Mozilla/5.0\"}\n",
    "\n",
    "\n",
    "# Loop for pages 1 to numpages\n",
    "for n in range(1,numpages+1):\n",
    "    url = myurl + extrastring[n-1]\n",
    "    source = requests.get(url,headers=header).text\n",
    "    mysoup = BeautifulSoup(source,'lxml')\n",
    "\n",
    "    ### University URLs\n",
    "    for myUname in mysoup.find_all(\"h2\",class_=\"h-taut\"): # All tags with university name\n",
    "        univurl.append(myUname.a['href'])\n",
    "# Append URL list to dataframe\n",
    "tmp = pd.DataFrame({'USN_URL':univurl[0:len(globalscores)]})\n",
    "USN_df = USN_df.join(tmp)\n",
    "USN_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the URL retrieved, the data used to score the universities is available. The following code retrieves such data. Let's try and study with the first element of the URL list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.usnews.com/education/best-global-universities/universidade-de-sao-paulo-500437\n"
     ]
    }
   ],
   "source": [
    "details_url = USN_df['USN_URL'][0]\n",
    "print(details_url)\n",
    "header = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko)'\n",
    "          +' Chrome/64.0.3282.186 Safari/537.36','Accept': 'application/json, text/javascript, */*; q=0.01'}\n",
    "header = {\"User-Agent\":\"Mozilla/5.0\"}\n",
    "source = requests.get(details_url,headers=header).text\n",
    "mysoup = BeautifulSoup(source,'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Av. Prof. Almeida Prado, nº1280 - Butantã São Paulo, 05508-070 Brazil\n"
     ]
    }
   ],
   "source": [
    "# Getting the address (location)\n",
    "maincontent = mysoup.find('div',class_='maincontent')\n",
    "dirdata = maincontent.find('div',class_='directory-data')\n",
    "address = ''\n",
    "for data in dirdata.find_all('div'):\n",
    "    address = address + data.text + ' '\n",
    "address = address.strip()\n",
    "print(address)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Av. Prof. Almeida Prado, nº1280 - Butantã São Paulo, 05508-070 Brazil\n",
      "http://www5.usp.br/en/ \n"
     ]
    }
   ],
   "source": [
    "# Getting the webpage\n",
    "# Both location and webpage are under the same tree of tags... I have to get both of them in one shot!\n",
    "maincontent = mysoup.find_all('div',class_='directory-data')\n",
    "address = maincontent[0]\n",
    "webpage = maincontent[1]\n",
    "text = ''\n",
    "for data in address.find_all('div'):\n",
    "    text = text + data.text + ' '\n",
    "address = text.strip()\n",
    "webpage = webpage.find('a')['href']\n",
    "print(address)\n",
    "print(webpage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Detail</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Total number of students</td>\n",
       "      <td>83,214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Number of international students</td>\n",
       "      <td>3,161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Total number of academic staff</td>\n",
       "      <td>5,230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Number of international staff</td>\n",
       "      <td>258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Number of undergraduate degrees awarded</td>\n",
       "      <td>8,207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Number of master's degrees awarded</td>\n",
       "      <td>3,742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Number of doctoral degrees awarded</td>\n",
       "      <td>3,078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Number of research only staff</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Number of new undergraduate students</td>\n",
       "      <td>10,978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Number of new master's students</td>\n",
       "      <td>4,697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Number of new doctoral students</td>\n",
       "      <td>3,308</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Detail   Value\n",
       "0                  Total number of students  83,214\n",
       "1          Number of international students   3,161\n",
       "2            Total number of academic staff   5,230\n",
       "3             Number of international staff     258\n",
       "4   Number of undergraduate degrees awarded   8,207\n",
       "5        Number of master's degrees awarded   3,742\n",
       "6        Number of doctoral degrees awarded   3,078\n",
       "7             Number of research only staff       0\n",
       "8      Number of new undergraduate students  10,978\n",
       "9           Number of new master's students   4,697\n",
       "10          Number of new doctoral students   3,308"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting university details\n",
    "maincontent = mysoup.find('div',id='directoryPageSection-institution-data')\n",
    "#print(maincontent.prettify())\n",
    "detailname = []\n",
    "detailval = []\n",
    "for name in maincontent.find_all('div',class_=\"t-dim\"):\n",
    "    detailname.append(name.text.strip())\n",
    "for value in maincontent.find_all('div',class_=\"right t-strong\"):\n",
    "    detailval.append(value.text.strip())\n",
    "# Print dataframe\n",
    "tmp = pd.DataFrame({'Detail':detailname,'Value':detailval})\n",
    "tmp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataframe cannot be joined to the ranking dataframe as it is here. The best way to do it is to generate a dataframe with columns labeled as the \"Detail\" shown here, and rows with the \"Values\". In that way, after filling the whole dataframe it can be straightforwardly joined to the ranking dataframe. Something like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total number of students</th>\n",
       "      <th>Number of international students</th>\n",
       "      <th>Total number of academic staff</th>\n",
       "      <th>Number of international staff</th>\n",
       "      <th>Number of undergraduate degrees awarded</th>\n",
       "      <th>Number of master's degrees awarded</th>\n",
       "      <th>Number of doctoral degrees awarded</th>\n",
       "      <th>Number of research only staff</th>\n",
       "      <th>Number of new undergraduate students</th>\n",
       "      <th>Number of new master's students</th>\n",
       "      <th>Number of new doctoral students</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>83,214</td>\n",
       "      <td>3,161</td>\n",
       "      <td>5,230</td>\n",
       "      <td>258</td>\n",
       "      <td>8,207</td>\n",
       "      <td>3,742</td>\n",
       "      <td>3,078</td>\n",
       "      <td>0</td>\n",
       "      <td>10,978</td>\n",
       "      <td>4,697</td>\n",
       "      <td>3,308</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Total number of students Number of international students  \\\n",
       "0                   83,214                            3,161   \n",
       "\n",
       "  Total number of academic staff Number of international staff  \\\n",
       "0                          5,230                           258   \n",
       "\n",
       "  Number of undergraduate degrees awarded Number of master's degrees awarded  \\\n",
       "0                                   8,207                              3,742   \n",
       "\n",
       "  Number of doctoral degrees awarded Number of research only staff  \\\n",
       "0                              3,078                             0   \n",
       "\n",
       "  Number of new undergraduate students Number of new master's students  \\\n",
       "0                               10,978                           4,697   \n",
       "\n",
       "  Number of new doctoral students  \n",
       "0                           3,308  "
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp = tmp.T\n",
    "tmp.rename(columns=tmp.iloc[0],inplace=True)\n",
    "tmp = tmp.drop(['Detail'])\n",
    "tmp.reset_index(inplace=True,drop=True)\n",
    "tmp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, some of the pages do not have data at all. And worse, some of them have some of the data (which denies the possibility of just neglecting pages without data). Thus, it is better to create a dictionary for the details of each university. This is taken into account in the definition of the following code, which retrieves the a available details of each university."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time # For sleep()\n",
    "\n",
    "# Initialize data fields\n",
    "details = [] # list, each element will be a dictionary with details\n",
    "dictkeys = ['Address','Webpage',\n",
    "            'Total number of students', 'Number of international students', 'Total number of academic staff', \n",
    "            'Number of international staff', 'Number of undergraduate degrees awarded', \"Number of master's degrees awarded\", \n",
    "            'Number of doctoral degrees awarded', 'Number of research only staff', 'Number of new undergraduate students', \n",
    "            \"Number of new master's students\", 'Number of new doctoral students']\n",
    "\n",
    "# Loop over different URLs given in USN_df['USN_URL']\n",
    "maxurl = len(USN_df['USN_URL'])\n",
    "\n",
    "header = {\"User-Agent\":\"Mozilla/5.0\"}\n",
    "for urlnum in range(maxurl):\n",
    "    time.sleep(1) # Wait 1 second so the server will not deny my next calls\n",
    "    mydict = {x:None for x in dictkeys} # Initialize dictionary for current university page\n",
    "    details_url = USN_df['USN_URL'][urlnum]\n",
    "    source = requests.get(details_url,headers=header).text\n",
    "    mysoup = BeautifulSoup(source,'lxml')\n",
    "###    # To check that the access was not denied!\n",
    "###    print('HEAD.TITLE of retrieved mysoup object: ',mysoup.head.title)\n",
    "    \n",
    "    # Getting the webpage\n",
    "    maincontent = mysoup.find_all('div',class_='directory-data')\n",
    "    address = maincontent[0]\n",
    "    webpage = maincontent[1]\n",
    "    text = ''\n",
    "    for data in address.find_all('div'):\n",
    "        text = text + data.text + ' '\n",
    "    mydict['Address'] = text.strip()\n",
    "    mydict['Webpage'] = webpage.find('a')['href']\n",
    "\n",
    "    # Getting university details\n",
    "    maincontent = mysoup.find('div',id='directoryPageSection-institution-data')\n",
    "    # Initialize details lists\n",
    "    detailname = []\n",
    "    detailvalue = []\n",
    "    for name in maincontent.find_all('div',class_=\"t-dim\"):\n",
    "        detailname.append(name.text.strip())\n",
    "    for value in maincontent.find_all('div',class_=\"right t-strong\"):\n",
    "        detailvalue.append(value.text.strip())\n",
    "    # At this moment I have a list of details name and values. Put them in the dictionary\n",
    "    for i in range(len(detailname)):\n",
    "        mydict[detailname[i]] = detailvalue[i]\n",
    "    details.append(mydict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Address</th>\n",
       "      <th>Webpage</th>\n",
       "      <th>Total number of students</th>\n",
       "      <th>Number of international students</th>\n",
       "      <th>Total number of academic staff</th>\n",
       "      <th>Number of international staff</th>\n",
       "      <th>Number of undergraduate degrees awarded</th>\n",
       "      <th>Number of master's degrees awarded</th>\n",
       "      <th>Number of doctoral degrees awarded</th>\n",
       "      <th>Number of research only staff</th>\n",
       "      <th>Number of new undergraduate students</th>\n",
       "      <th>Number of new master's students</th>\n",
       "      <th>Number of new doctoral students</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Av. Prof. Almeida Prado, nº1280 - Butantã São ...</td>\n",
       "      <td>http://www5.usp.br/en/</td>\n",
       "      <td>83,214</td>\n",
       "      <td>3,161</td>\n",
       "      <td>5,230</td>\n",
       "      <td>258</td>\n",
       "      <td>8,207</td>\n",
       "      <td>3,742</td>\n",
       "      <td>3,078</td>\n",
       "      <td>0</td>\n",
       "      <td>10,978</td>\n",
       "      <td>4,697</td>\n",
       "      <td>3,308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Avda.  Libertador Bernardo O'Higgins 340 Santi...</td>\n",
       "      <td>http://www.uc.cl/</td>\n",
       "      <td>28,541</td>\n",
       "      <td>2,007</td>\n",
       "      <td>1,900</td>\n",
       "      <td>207</td>\n",
       "      <td>2,981</td>\n",
       "      <td>None</td>\n",
       "      <td>121</td>\n",
       "      <td>270</td>\n",
       "      <td>5,190</td>\n",
       "      <td>None</td>\n",
       "      <td>268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Campus Universitário Zeferino Vaz Campinas, Sã...</td>\n",
       "      <td>http://www.unicamp.br/unicamp/?language=en</td>\n",
       "      <td>28,795</td>\n",
       "      <td>974</td>\n",
       "      <td>1,906</td>\n",
       "      <td>106</td>\n",
       "      <td>2,500</td>\n",
       "      <td>1,342</td>\n",
       "      <td>997</td>\n",
       "      <td>94</td>\n",
       "      <td>3,353</td>\n",
       "      <td>2,110</td>\n",
       "      <td>1,511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Av. Pedro Calmon, 550 Rio de Janeiro, 21941-90...</td>\n",
       "      <td>http://www.ufrj.br/</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Viamonte 430 st. Buenos Aires City, Buenos Air...</td>\n",
       "      <td>http://www.uba.ar/ingles/index03.php</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Av. Universidad 3000, Copilco Universidad, Coy...</td>\n",
       "      <td>http://www.unam.mx/index/en</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Av. Libertador Bernardo O'Higgins 1058 Santiag...</td>\n",
       "      <td>http://www.uchile.cl/english</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Carrera Primera #18A-12 Bogotá, DC Colombia</td>\n",
       "      <td>http://www.uniandes.edu.co/</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Av. Espana 1680 Valparaiso, Valparaiso Chile</td>\n",
       "      <td>http://www.usm.cl/</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Av. Paulo Gama, 110 Porto Alegre, Rio Grande d...</td>\n",
       "      <td>http://www.ufrgs.br/english/home</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Address  \\\n",
       "0  Av. Prof. Almeida Prado, nº1280 - Butantã São ...   \n",
       "1  Avda.  Libertador Bernardo O'Higgins 340 Santi...   \n",
       "2  Campus Universitário Zeferino Vaz Campinas, Sã...   \n",
       "3  Av. Pedro Calmon, 550 Rio de Janeiro, 21941-90...   \n",
       "4  Viamonte 430 st. Buenos Aires City, Buenos Air...   \n",
       "5  Av. Universidad 3000, Copilco Universidad, Coy...   \n",
       "6  Av. Libertador Bernardo O'Higgins 1058 Santiag...   \n",
       "7        Carrera Primera #18A-12 Bogotá, DC Colombia   \n",
       "8       Av. Espana 1680 Valparaiso, Valparaiso Chile   \n",
       "9  Av. Paulo Gama, 110 Porto Alegre, Rio Grande d...   \n",
       "\n",
       "                                       Webpage Total number of students  \\\n",
       "0                      http://www5.usp.br/en/                    83,214   \n",
       "1                           http://www.uc.cl/                    28,541   \n",
       "2  http://www.unicamp.br/unicamp/?language=en                    28,795   \n",
       "3                         http://www.ufrj.br/                      None   \n",
       "4         http://www.uba.ar/ingles/index03.php                     None   \n",
       "5                  http://www.unam.mx/index/en                     None   \n",
       "6                http://www.uchile.cl/english                      None   \n",
       "7                  http://www.uniandes.edu.co/                     None   \n",
       "8                           http://www.usm.cl/                     None   \n",
       "9             http://www.ufrgs.br/english/home                     None   \n",
       "\n",
       "  Number of international students Total number of academic staff  \\\n",
       "0                            3,161                          5,230   \n",
       "1                            2,007                          1,900   \n",
       "2                              974                          1,906   \n",
       "3                             None                           None   \n",
       "4                             None                           None   \n",
       "5                             None                           None   \n",
       "6                             None                           None   \n",
       "7                             None                           None   \n",
       "8                             None                           None   \n",
       "9                             None                           None   \n",
       "\n",
       "  Number of international staff Number of undergraduate degrees awarded  \\\n",
       "0                           258                                   8,207   \n",
       "1                           207                                   2,981   \n",
       "2                           106                                   2,500   \n",
       "3                          None                                    None   \n",
       "4                          None                                    None   \n",
       "5                          None                                    None   \n",
       "6                          None                                    None   \n",
       "7                          None                                    None   \n",
       "8                          None                                    None   \n",
       "9                          None                                    None   \n",
       "\n",
       "  Number of master's degrees awarded Number of doctoral degrees awarded  \\\n",
       "0                              3,742                              3,078   \n",
       "1                               None                                121   \n",
       "2                              1,342                                997   \n",
       "3                               None                               None   \n",
       "4                               None                               None   \n",
       "5                               None                               None   \n",
       "6                               None                               None   \n",
       "7                               None                               None   \n",
       "8                               None                               None   \n",
       "9                               None                               None   \n",
       "\n",
       "  Number of research only staff Number of new undergraduate students  \\\n",
       "0                             0                               10,978   \n",
       "1                           270                                5,190   \n",
       "2                            94                                3,353   \n",
       "3                          None                                 None   \n",
       "4                          None                                 None   \n",
       "5                          None                                 None   \n",
       "6                          None                                 None   \n",
       "7                          None                                 None   \n",
       "8                          None                                 None   \n",
       "9                          None                                 None   \n",
       "\n",
       "  Number of new master's students Number of new doctoral students  \n",
       "0                           4,697                           3,308  \n",
       "1                            None                             268  \n",
       "2                           2,110                           1,511  \n",
       "3                            None                            None  \n",
       "4                            None                            None  \n",
       "5                            None                            None  \n",
       "6                            None                            None  \n",
       "7                            None                            None  \n",
       "8                            None                            None  \n",
       "9                            None                            None  "
      ]
     },
     "execution_count": 342,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extended_df = pd.DataFrame.from_dict(details)\n",
    "extended_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, the merging of this extended dataframe with the ranking dataframe is straightforward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "USN_fulldf = USN_df.join(extended_df)\n",
    "USN_fulldf.to_csv('USN_dataframe.csv',encoding=\"utf-8-sig\")\n",
    "USN_fulldf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This ends the data retrieving for source number two. YAY!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Source three: QS (Quacquarelli Symonds) Top Universities</h4>\n",
    "The third source of data will be the ranking by <a href=\"https://www.topuniversities.com/university-rankings/world-university-rankings/2020\">QS (Quacquarelli Symonds) Top Universities</a>. <b>SAY SOMETHING ABOUT THE SOURCE...</b>. he data will be restricted to the Latin American countries in their search results. <br><br>\n",
    "Looking at the structure of the page, the data is not in a table but in a set of <code>div</code> tags with <code>class=\"sep\"</code>. A concerning details is that it is not possible to ask for the full list in one shot (there is no option like \"Show all\" in this source), but this will be solved later. For the first page of results for the Latin American universities, the retrieving code is the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "myurl=\"https://www.topuniversities.com/university-rankings/world-university-rankings/2020\"\n",
    "#header = {'User-Agent': 'Mozilla/5.0 (Windows NT 6.1; WOW64; rv:50.0) Gecko/20100101 Firefox/50.0'}\n",
    "header = {\"User-Agent\":\"Mozilla/5.0\"}\n",
    "source = requests.get(myurl,headers=header).text\n",
    "mysoup = BeautifulSoup(source,'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#content = mysoup.find('div',class_='panel-pane pane-block pane-qs-rankings-datatables-0')\n",
    "content = mysoup.find('table',id='qs-rankings')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, an empty table. Further reading about this, the table is generated by a script. Checking in the developer tools in the browser, the files that contain the actual information are located in the URLs given in the next code cell. Those are the ones to be retrieved and processed to generate the corresponding dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "urlranks = \"https://www.topuniversities.com/sites/default/files/qs-rankings-data/914824.txt\"\n",
    "urlindicators = \"https://www.topuniversities.com/sites/default/files/qs-rankings-data/914824_indicators.txt\"\n",
    "\n",
    "header = {\"User-Agent\":\"Mozilla/5.0\"}\n",
    "\n",
    "sourceranks = requests.get(urlranks,headers=header).text # Without .text, it gets the response in JSON format\n",
    "sourceindic = requests.get(urlindicators,headers=header).text # Without .text, it gets the response in JSON format\n",
    "mysoupranks = BeautifulSoup(sourceranks,'lxml')\n",
    "mysoupindic = BeautifulSoup(sourceindic,'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Region</th>\n",
       "      <th>Country</th>\n",
       "      <th>GlobalScore</th>\n",
       "      <th>GlobalRank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Universidad de Buenos Aires (UBA)</td>\n",
       "      <td>Latin America</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>66</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Universidad Nacional Autónoma de México  (UNAM)</td>\n",
       "      <td>Latin America</td>\n",
       "      <td>Mexico</td>\n",
       "      <td>58.8</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Universidade de São Paulo</td>\n",
       "      <td>Latin America</td>\n",
       "      <td>Brazil</td>\n",
       "      <td>55.5</td>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pontificia Universidad Católica de Chile (UC)</td>\n",
       "      <td>Latin America</td>\n",
       "      <td>Chile</td>\n",
       "      <td>53.4</td>\n",
       "      <td>127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tecnológico de Monterrey</td>\n",
       "      <td>Latin America</td>\n",
       "      <td>Mexico</td>\n",
       "      <td>48.5</td>\n",
       "      <td>158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Universidad de Chile</td>\n",
       "      <td>Latin America</td>\n",
       "      <td>Chile</td>\n",
       "      <td>45</td>\n",
       "      <td>189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Universidade Estadual de Campinas (Unicamp)</td>\n",
       "      <td>Latin America</td>\n",
       "      <td>Brazil</td>\n",
       "      <td>42.1</td>\n",
       "      <td>214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Universidad de los Andes</td>\n",
       "      <td>Latin America</td>\n",
       "      <td>Colombia</td>\n",
       "      <td>39.6</td>\n",
       "      <td>234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Universidad Nacional de Colombia</td>\n",
       "      <td>Latin America</td>\n",
       "      <td>Colombia</td>\n",
       "      <td>37.5</td>\n",
       "      <td>253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Pontificia Universidad Católica Argentina</td>\n",
       "      <td>Latin America</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>31.7</td>\n",
       "      <td>344</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Name         Region    Country  \\\n",
       "0                Universidad de Buenos Aires (UBA)  Latin America  Argentina   \n",
       "1  Universidad Nacional Autónoma de México  (UNAM)  Latin America     Mexico   \n",
       "2                        Universidade de São Paulo  Latin America     Brazil   \n",
       "3    Pontificia Universidad Católica de Chile (UC)  Latin America      Chile   \n",
       "4                         Tecnológico de Monterrey  Latin America     Mexico   \n",
       "5                             Universidad de Chile  Latin America      Chile   \n",
       "6      Universidade Estadual de Campinas (Unicamp)  Latin America     Brazil   \n",
       "7                         Universidad de los Andes  Latin America   Colombia   \n",
       "8                 Universidad Nacional de Colombia  Latin America   Colombia   \n",
       "9        Pontificia Universidad Católica Argentina  Latin America  Argentina   \n",
       "\n",
       "  GlobalScore  GlobalRank  \n",
       "0          66          74  \n",
       "1        58.8         103  \n",
       "2        55.5         116  \n",
       "3        53.4         127  \n",
       "4        48.5         158  \n",
       "5          45         189  \n",
       "6        42.1         214  \n",
       "7        39.6         234  \n",
       "8        37.5         253  \n",
       "9        31.7         344  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "import re\n",
    "\n",
    "# Mysoupranks is a single paragraph (p) of HTML which contains the text file\n",
    "#   with the information required. It can be converted to a dictionary. However\n",
    "#   it has only one key with all the data inside. The following code will break\n",
    "#   the information in order to get individual data in a manageable way.\n",
    "import json\n",
    "diction = json.loads(mysoupranks.text)\n",
    "\n",
    "# By checking the structure of \"data\", the useful data is:\n",
    "#   Continent is in ['region'] (I can get the Latin American universities with this)\n",
    "#   Country is in ['country']\n",
    "#   University name is in ['title']\n",
    "#   Global score is in ['score']\n",
    "#   Rank is in ['rank_display']\n",
    "\n",
    "details = [] # list, each element will be a dictionary with details\n",
    "dictkeys = ['Name','Region','Country','GlobalScore','GlobalRank']\n",
    "## interests = ['title','region','country','score','rank_display']\n",
    "\n",
    "for i in range(len(diction['data'])):\n",
    "    if diction['data'][i]['region'] == 'Latin America':\n",
    "        mydict = {x:None for x in dictkeys} # Initialize dictionary for current university\n",
    "        mydict['Name']        = diction['data'][i]['title']\n",
    "        mydict['Region']      = diction['data'][i]['region']\n",
    "        mydict['Country']     = diction['data'][i]['country']\n",
    "        mydict['GlobalScore'] = diction['data'][i]['score']\n",
    "        # Some ranks are tied, and have an \"=\" in its value\n",
    "        mydict['GlobalRank']  = int(re.findall(\"[0-9]+\",str(diction['data'][i]['rank_display']))[0])\n",
    "        # The final [0] is because re.findall returns a list, in this case with one element.\n",
    "        details.append(mydict)\n",
    "basic_df = pd.DataFrame.from_dict(details)\n",
    "basic_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, it is the turn of the indicators to be processed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Citations per Faculty =  100\n",
      "International Students =  87.3\n",
      "International Faculty =  99.4\n",
      "Faculty Student =  100\n",
      "Employer Reputation =  81.2\n",
      "Academic Reputation =  97.8\n"
     ]
    }
   ],
   "source": [
    "indicators = json.loads(mysoupindic.text)\n",
    "indicators.pop('columns')\n",
    "### In columns, I have this data...\n",
    "#   {'data': '3791737',\n",
    "#     'title': '<div class=\"td-wrap\"><div class=\"labl\"><div>Citations per Faculty</div></div><div class=\"sorter\"></div></div>',\n",
    "#     'searchable': False,\n",
    "#     'orderable': False}\n",
    "# It seems that instead of names, they used ID numbers for the indicators. I found these:\n",
    "#     ID = 3791737, for indicator 'Citations per Faculty'\n",
    "#     ID = 3791738, for indicator 'International Students'\n",
    "#     ID = 3791739, for indicator 'International Faculty'\n",
    "#     ID = 3791740, for indicator 'Faculty Student'\n",
    "#     ID = 3791741, for indicator 'Employer Reputation'\n",
    "#     ID = 3791742, for indicator 'Academic Reputation'\n",
    "\n",
    "# The elements in the indicators are strings made of HTML code. I need to parse them\n",
    "#   before being able to extract the value of the indicator\n",
    "#   actual_value = BeautifulSoup(indicators['data'][0]['3791737'],'lxml').text\n",
    "\n",
    "# Example, for university 5 (index 4)\n",
    "print('Citations per Faculty = ',BeautifulSoup(indicators['data'][4]['3791737'],'lxml').text)\n",
    "print('International Students = ',BeautifulSoup(indicators['data'][4]['3791738'],'lxml').text)\n",
    "print('International Faculty = ',BeautifulSoup(indicators['data'][4]['3791739'],'lxml').text)\n",
    "print('Faculty Student = ',BeautifulSoup(indicators['data'][4]['3791740'],'lxml').text)\n",
    "print('Employer Reputation = ',BeautifulSoup(indicators['data'][4]['3791741'],'lxml').text)\n",
    "print('Academic Reputation = ',BeautifulSoup(indicators['data'][4]['3791742'],'lxml').text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Citations_per_Faculty</th>\n",
       "      <th>International_Students</th>\n",
       "      <th>International_Faculty</th>\n",
       "      <th>Faculty_Student</th>\n",
       "      <th>Employer_Reputation</th>\n",
       "      <th>Academic_Reputation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.4</td>\n",
       "      <td>64.7</td>\n",
       "      <td>50.7</td>\n",
       "      <td>77.4</td>\n",
       "      <td>91.3</td>\n",
       "      <td>87.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.8</td>\n",
       "      <td>4.3</td>\n",
       "      <td>13.8</td>\n",
       "      <td>57.6</td>\n",
       "      <td>91</td>\n",
       "      <td>90.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>35.2</td>\n",
       "      <td>3.7</td>\n",
       "      <td>8.9</td>\n",
       "      <td>25.2</td>\n",
       "      <td>73.3</td>\n",
       "      <td>88.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13.6</td>\n",
       "      <td>4.2</td>\n",
       "      <td>19.4</td>\n",
       "      <td>28.6</td>\n",
       "      <td>95.5</td>\n",
       "      <td>85.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.6</td>\n",
       "      <td>18.4</td>\n",
       "      <td>98.2</td>\n",
       "      <td>89.5</td>\n",
       "      <td>88.9</td>\n",
       "      <td>36.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>14.5</td>\n",
       "      <td>8.4</td>\n",
       "      <td>10.1</td>\n",
       "      <td>16.3</td>\n",
       "      <td>90.8</td>\n",
       "      <td>71.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>32.7</td>\n",
       "      <td>4.3</td>\n",
       "      <td>9.9</td>\n",
       "      <td>21.1</td>\n",
       "      <td>34.5</td>\n",
       "      <td>67.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8.1</td>\n",
       "      <td>3.1</td>\n",
       "      <td>32.1</td>\n",
       "      <td>27.6</td>\n",
       "      <td>87.9</td>\n",
       "      <td>54.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5.3</td>\n",
       "      <td>1.3</td>\n",
       "      <td>8.3</td>\n",
       "      <td>11.1</td>\n",
       "      <td>89.7</td>\n",
       "      <td>61.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.1</td>\n",
       "      <td>13.2</td>\n",
       "      <td>2.9</td>\n",
       "      <td>95.3</td>\n",
       "      <td>44.3</td>\n",
       "      <td>17.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Citations_per_Faculty International_Students International_Faculty  \\\n",
       "0                   2.4                   64.7                  50.7   \n",
       "1                   3.8                    4.3                  13.8   \n",
       "2                  35.2                    3.7                   8.9   \n",
       "3                  13.6                    4.2                  19.4   \n",
       "4                   4.6                   18.4                  98.2   \n",
       "5                  14.5                    8.4                  10.1   \n",
       "6                  32.7                    4.3                   9.9   \n",
       "7                   8.1                    3.1                  32.1   \n",
       "8                   5.3                    1.3                   8.3   \n",
       "9                   1.1                   13.2                   2.9   \n",
       "\n",
       "  Faculty_Student Employer_Reputation Academic_Reputation  \n",
       "0            77.4                91.3                87.2  \n",
       "1            57.6                  91                90.9  \n",
       "2            25.2                73.3                88.3  \n",
       "3            28.6                95.5                85.2  \n",
       "4            89.5                88.9                36.9  \n",
       "5            16.3                90.8                71.6  \n",
       "6            21.1                34.5                67.5  \n",
       "7            27.6                87.9                54.4  \n",
       "8            11.1                89.7                61.5  \n",
       "9            95.3                44.3                17.7  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indicators = json.loads(mysoupindic.text)\n",
    "#indicators.pop('columns')\n",
    "\n",
    "# Initialize variables\n",
    "details = [] # list, each element will be a dictionary with details\n",
    "citperfalc = 'Citations_per_Faculty'\n",
    "interstude = 'International_Students'\n",
    "interfacul = 'International_Faculty'\n",
    "facstudent = 'Faculty_Student'\n",
    "employrepu = 'Employer_Reputation'\n",
    "academrepu = 'Academic_Reputation'\n",
    "dictkeys = [citperfalc,interstude,interfacul,facstudent,employrepu,academrepu]\n",
    "indicators['data'][0]['region']\n",
    "\n",
    "for i in range(len(indicators['data'])):\n",
    "    if indicators['data'][i]['region'] == 'Latin America':\n",
    "        mydict = {x:None for x in dictkeys} # Initialize dictionary for current university\n",
    "        try:\n",
    "            mydict[citperfalc] = BeautifulSoup(indicators['data'][i]['3791737'],'lxml').text\n",
    "        except:\n",
    "            pass\n",
    "        try:\n",
    "            mydict[interstude] = BeautifulSoup(indicators['data'][i]['3791738'],'lxml').text\n",
    "        except:\n",
    "            pass\n",
    "        try:\n",
    "            mydict[interfacul] = BeautifulSoup(indicators['data'][i]['3791739'],'lxml').text\n",
    "        except:\n",
    "            pass\n",
    "        try:\n",
    "            mydict[facstudent] = BeautifulSoup(indicators['data'][i]['3791740'],'lxml').text\n",
    "        except:\n",
    "            pass\n",
    "        try:\n",
    "            mydict[employrepu] = BeautifulSoup(indicators['data'][i]['3791741'],'lxml').text\n",
    "        except:\n",
    "            pass\n",
    "        try:\n",
    "            mydict[academrepu] = BeautifulSoup(indicators['data'][i]['3791742'],'lxml').text\n",
    "        except:\n",
    "            pass\n",
    "        details.append(mydict)\n",
    "\n",
    "indic_df = pd.DataFrame.from_dict(details)\n",
    "indic_df.head(10)\n",
    "# For the 'data' (remaining) key, the interests are:\n",
    "# interests = ['region' = 'Latin America','overall_rank','uni'.text,\n",
    "#              '','','','','',]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, the merging of this extended dataframe with the ranking dataframe is straightforward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Region</th>\n",
       "      <th>Country</th>\n",
       "      <th>GlobalScore</th>\n",
       "      <th>GlobalRank</th>\n",
       "      <th>Citations_per_Faculty</th>\n",
       "      <th>International_Students</th>\n",
       "      <th>International_Faculty</th>\n",
       "      <th>Faculty_Student</th>\n",
       "      <th>Employer_Reputation</th>\n",
       "      <th>Academic_Reputation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Universidad de Buenos Aires (UBA)</td>\n",
       "      <td>Latin America</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>66</td>\n",
       "      <td>74</td>\n",
       "      <td>2.4</td>\n",
       "      <td>64.7</td>\n",
       "      <td>50.7</td>\n",
       "      <td>77.4</td>\n",
       "      <td>91.3</td>\n",
       "      <td>87.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Universidad Nacional Autónoma de México  (UNAM)</td>\n",
       "      <td>Latin America</td>\n",
       "      <td>Mexico</td>\n",
       "      <td>58.8</td>\n",
       "      <td>103</td>\n",
       "      <td>3.8</td>\n",
       "      <td>4.3</td>\n",
       "      <td>13.8</td>\n",
       "      <td>57.6</td>\n",
       "      <td>91</td>\n",
       "      <td>90.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Universidade de São Paulo</td>\n",
       "      <td>Latin America</td>\n",
       "      <td>Brazil</td>\n",
       "      <td>55.5</td>\n",
       "      <td>116</td>\n",
       "      <td>35.2</td>\n",
       "      <td>3.7</td>\n",
       "      <td>8.9</td>\n",
       "      <td>25.2</td>\n",
       "      <td>73.3</td>\n",
       "      <td>88.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pontificia Universidad Católica de Chile (UC)</td>\n",
       "      <td>Latin America</td>\n",
       "      <td>Chile</td>\n",
       "      <td>53.4</td>\n",
       "      <td>127</td>\n",
       "      <td>13.6</td>\n",
       "      <td>4.2</td>\n",
       "      <td>19.4</td>\n",
       "      <td>28.6</td>\n",
       "      <td>95.5</td>\n",
       "      <td>85.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tecnológico de Monterrey</td>\n",
       "      <td>Latin America</td>\n",
       "      <td>Mexico</td>\n",
       "      <td>48.5</td>\n",
       "      <td>158</td>\n",
       "      <td>4.6</td>\n",
       "      <td>18.4</td>\n",
       "      <td>98.2</td>\n",
       "      <td>89.5</td>\n",
       "      <td>88.9</td>\n",
       "      <td>36.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>Universidade Federal de São Carlos (UFSCar)</td>\n",
       "      <td>Latin America</td>\n",
       "      <td>Brazil</td>\n",
       "      <td></td>\n",
       "      <td>801</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>24</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>Universidade Federal de Viçosa (UFV)</td>\n",
       "      <td>Latin America</td>\n",
       "      <td>Brazil</td>\n",
       "      <td></td>\n",
       "      <td>801</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>Universidade Federal do Paraná - UFPR</td>\n",
       "      <td>Latin America</td>\n",
       "      <td>Brazil</td>\n",
       "      <td></td>\n",
       "      <td>801</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>Universidade Federal de Pernambuco (UFPE)</td>\n",
       "      <td>Latin America</td>\n",
       "      <td>Brazil</td>\n",
       "      <td></td>\n",
       "      <td>801</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>28.5</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>Universidade Federal Fluminense</td>\n",
       "      <td>Latin America</td>\n",
       "      <td>Brazil</td>\n",
       "      <td></td>\n",
       "      <td>801</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>38.1</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>88 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Name         Region    Country  \\\n",
       "0                 Universidad de Buenos Aires (UBA)  Latin America  Argentina   \n",
       "1   Universidad Nacional Autónoma de México  (UNAM)  Latin America     Mexico   \n",
       "2                         Universidade de São Paulo  Latin America     Brazil   \n",
       "3     Pontificia Universidad Católica de Chile (UC)  Latin America      Chile   \n",
       "4                          Tecnológico de Monterrey  Latin America     Mexico   \n",
       "..                                              ...            ...        ...   \n",
       "83      Universidade Federal de São Carlos (UFSCar)  Latin America     Brazil   \n",
       "84             Universidade Federal de Viçosa (UFV)  Latin America     Brazil   \n",
       "85            Universidade Federal do Paraná - UFPR  Latin America     Brazil   \n",
       "86        Universidade Federal de Pernambuco (UFPE)  Latin America     Brazil   \n",
       "87                  Universidade Federal Fluminense  Latin America     Brazil   \n",
       "\n",
       "   GlobalScore  GlobalRank Citations_per_Faculty International_Students  \\\n",
       "0           66          74                   2.4                   64.7   \n",
       "1         58.8         103                   3.8                    4.3   \n",
       "2         55.5         116                  35.2                    3.7   \n",
       "3         53.4         127                  13.6                    4.2   \n",
       "4         48.5         158                   4.6                   18.4   \n",
       "..         ...         ...                   ...                    ...   \n",
       "83                     801                  None                   None   \n",
       "84                     801                  None                   None   \n",
       "85                     801                  None                   None   \n",
       "86                     801                  None                   None   \n",
       "87                     801                  None                   None   \n",
       "\n",
       "   International_Faculty Faculty_Student Employer_Reputation  \\\n",
       "0                   50.7            77.4                91.3   \n",
       "1                   13.8            57.6                  91   \n",
       "2                    8.9            25.2                73.3   \n",
       "3                   19.4            28.6                95.5   \n",
       "4                   98.2            89.5                88.9   \n",
       "..                   ...             ...                 ...   \n",
       "83                  None              24                None   \n",
       "84                  None            None                None   \n",
       "85                  None            None                None   \n",
       "86                  None            28.5                None   \n",
       "87                  None            38.1                None   \n",
       "\n",
       "   Academic_Reputation  \n",
       "0                 87.2  \n",
       "1                 90.9  \n",
       "2                 88.3  \n",
       "3                 85.2  \n",
       "4                 36.9  \n",
       "..                 ...  \n",
       "83                None  \n",
       "84                None  \n",
       "85                None  \n",
       "86                None  \n",
       "87                None  \n",
       "\n",
       "[88 rows x 11 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "QSTopU_fulldf = basic_df.join(indic_df)\n",
    "QSTopU_fulldf.to_csv('QSTopU_dataframe.csv',encoding=\"utf-8-sig\")\n",
    "QSTopU_fulldf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr></hr><hr></hr><hr></hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr></hr><hr></hr><hr></hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>0.2 Getting coordinates for the neighborhoods from Problem 2</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert file to dataframe\n",
    "toronto_df = pd.read_csv('toronto_data.csv')\n",
    "# Changing the name of the first column of downloaded data\n",
    "toronto_df.rename(columns={'Postal Code':'PostalCode'},inplace=True)\n",
    "# Merging provided data into the original dataframe\n",
    "# dataframe is the original data retrieved and cleaned from wikipedia\n",
    "# toronto_df is the downloaded data\n",
    "full_df = pd.merge(dataframe, toronto_df, on='PostalCode')\n",
    "full_df.drop_duplicates(inplace=True) # Dropping duplicated rows\n",
    "print('Shape of merged dataframe: ',merged.shape)\n",
    "full_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>1.1 Analyzing neighborhoods in Toronto</h4>\n",
    "The purpose of the following code is to group (cluster) different neighborhoods from Toronto in order to see how similar are some of them, and which type of facilities (venues) they have. Maybe you would like to visit neighborhoods with coffee shops and bars one day, and visit neighborhoods with malls and beauty shops another day!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get required packages and libraries ready\n",
    "\n",
    "import numpy as np # library to handle data in a vectorized manner\n",
    "\n",
    "# import pandas as pd # library for data analsysis\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "import json # library to handle JSON files\n",
    "\n",
    "!conda install -c conda-forge geopy --yes\n",
    "from geopy.geocoders import Nominatim # convert an address into latitude and longitude values\n",
    "\n",
    "# import requests # library to handle requests\n",
    "from pandas.io.json import json_normalize # tranform JSON file into a pandas dataframe\n",
    "\n",
    "# Matplotlib and associated plotting modules\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.colors as colors\n",
    "\n",
    "# import k-means from clustering stage\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "!conda install -c conda-forge folium=0.5.0 --yes\n",
    "import folium # map rendering library\n",
    "\n",
    "print('Libraries imported.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>1.2 A first look on Toronto</h4>\n",
    "Let's get some characteristics of the dataframe we have, as well as the location of Toronto in a map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many boroughs and neighborhoods does Toronto have?\n",
    "print('The dataframe \"full_df\" for Toronto has {} boroughs and {} neighborhoods.'\n",
    "      .format(len(full_df['Borough'].unique()),\n",
    "              full_df.shape[0]\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Where is Toronto?\n",
    "address = 'Toronto, Ontario'\n",
    "\n",
    "geolocator = Nominatim(user_agent=\"TO_explorer\")\n",
    "location = geolocator.geocode(address)\n",
    "latitude = location.latitude\n",
    "longitude = location.longitude\n",
    "print('The geographical coordinates of Toronto are {}, {}.'.format(latitude, longitude))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create map of Toronto using its latitude and longitude values\n",
    "map_toronto = folium.Map(location=[latitude, longitude], zoom_start=10)\n",
    "\n",
    "# Add markers of neighborhoods to map\n",
    "for lat, lng, borough, neighborhood, pcode in zip(full_df['Latitude'], full_df['Longitude'],\n",
    "                                                  full_df['Borough'], full_df['Neighborhood'],\n",
    "                                                  full_df['PostalCode']):\n",
    "    label = '{} ({}) {}'.format(neighborhood, borough, pcode)\n",
    "    label = folium.Popup(label, parse_html=True)\n",
    "    folium.CircleMarker(\n",
    "        [lat, lng],\n",
    "        radius=5,\n",
    "        popup=label,\n",
    "        color='blue',\n",
    "        fill=True,\n",
    "        fill_color='#3186cc',\n",
    "        fill_opacity=0.7,\n",
    "        parse_html=False).add_to(map_toronto) # Do not forget to add CircleMarker to the map!!  \n",
    "    \n",
    "map_toronto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to simplify the analysis, the exercise suggests to perform it only in boroughs that include 'Toronto' in its name. Let's extract that information:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the dataframe by appending the desired boroughs\n",
    "tmp = []\n",
    "for i,x in enumerate(full_df['Borough']): # Create an enumerated list of boroughs\n",
    "    if 'Toronto' in x: # Check if Toronto appears in the borough's name\n",
    "        tmp.append(full_df.iloc[i])\n",
    "\n",
    "justtoronto_df = pd.DataFrame(tmp).reset_index(drop=True) # Transform result to dataframe\n",
    "print('Shape of dataframe for Toronto boroughs: ',justtoronto_df.shape)\n",
    "justtoronto_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's adapt the map to the Toronto zone:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just changed \"full_df\" to \"justtoronto_df\"\n",
    "# And I will overwrite the previous map\n",
    "# Create map of Toronto using its latitude and longitude values\n",
    "map_toronto = folium.Map(location=[latitude, longitude], zoom_start=11) # Larger zoom\n",
    "\n",
    "# Add markers of neighborhoods to map\n",
    "for lat, lng, borough, neighborhood, pcode in zip(justtoronto_df['Latitude'], justtoronto_df['Longitude'],\n",
    "                                                  justtoronto_df['Borough'], justtoronto_df['Neighborhood'],\n",
    "                                                  justtoronto_df['PostalCode']):\n",
    "    label = '{} ({}) {}'.format(neighborhood, borough, pcode)\n",
    "    label = folium.Popup(label, parse_html=True)\n",
    "    folium.CircleMarker(\n",
    "        [lat, lng],\n",
    "        radius=5,\n",
    "        popup=label,\n",
    "        color='blue',\n",
    "        fill=True,\n",
    "        fill_color='#3186cc',\n",
    "        fill_opacity=0.7,\n",
    "        parse_html=False).add_to(map_toronto) # Do not forget to add CircleMarker to the map!!  \n",
    "    \n",
    "map_toronto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>2.1 Setting up Foursquare credentials</h4>\n",
    "Please don't eat up my calls credit! XD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLIENT_ID = 'RRYOHBWLN3VNML1RBPM0TRVDW2R41TKNWMZSH0VTOQKGNO2T' # your Foursquare ID\n",
    "CLIENT_SECRET = 'X22FCK21ZCS0UVXZ11TILJFRGXGWVMD5ZADQLIOSMDHHSHHN' # your Foursquare Secret\n",
    "VERSION = '20180605' # Foursquare API version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>2.2 Exploring one neighborhood</h4>\n",
    "In order to make things clear, let's establish the analysis plan using just one neighborhood. Choose by setting a number between 0 and 38 in the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up neighborhood to be analyzed\n",
    "nnum = 5\n",
    "\n",
    "myneigh = justtoronto_df.loc[nnum, 'Neighborhood']\n",
    "myneigh_lat = justtoronto_df.loc[nnum, 'Latitude'] # neighborhood latitude value\n",
    "myneigh_lon = justtoronto_df.loc[nnum, 'Longitude'] # neighborhood longitude value\n",
    "\n",
    "print('Your selected neighborhood is {}, located at (latitude,longitude) = ({},{}).'\n",
    "      .format(myneigh, myneigh_lat, myneigh_lon))\n",
    "print('Don\\'t forget to update this cell when you want to analyze other neighborhood!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code requests the top 100 venues in 500 meters around the location of your neighborhood:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LIMIT=100 # Remember the number and type of calls you have in your credit\n",
    "radius=500 # in meters\n",
    "# The URL structure is straighforward to read.\n",
    "# Just remember the information you have to provide for each type of request.\n",
    "url = 'https://api.foursquare.com/v2/venues/explore?&client_id={}&client_secret={}&v={}&ll={},{}&radius={}&limit={}'.format(\n",
    "           CLIENT_ID,\n",
    "           CLIENT_SECRET,\n",
    "           VERSION,\n",
    "           myneigh_lat,\n",
    "           myneigh_lon,\n",
    "           radius,\n",
    "           LIMIT)\n",
    "url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call to Foursquare. Do not abuse of this cell execution!!!\n",
    "results = requests.get(url).json()\n",
    "### results # Careful. Long result ahead. Uncomment just to be sure that it worked"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the information is in the <i>items</i> key. The following function <code>get_category_type</code> is used to extract the name of a category (remember the structure of the information in the <code>json</code> files)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that extracts the category of the venue\n",
    "def get_category_type(row):\n",
    "    try:\n",
    "        categories_list = row['categories']\n",
    "    except:\n",
    "        categories_list = row['venue.categories']\n",
    "        \n",
    "    if len(categories_list) == 0:\n",
    "        return None\n",
    "    else:\n",
    "        return categories_list[0]['name']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The previous function helps to clean the data from the request:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting \"items\" to work with a smaller amount of data\n",
    "venues = results['response']['groups'][0]['items']\n",
    "\n",
    "# Convert JSON-style data into a table\n",
    "nearby_venues = json_normalize(venues)\n",
    "\n",
    "# Getting only the columns we will use\n",
    "# The names come by looking at the json_normalize result\n",
    "filtered_columns = ['venue.name', 'venue.categories', 'venue.location.lat', 'venue.location.lng']\n",
    "nearby_venues = nearby_venues.loc[:, filtered_columns] # All rows, only the filtered columns\n",
    "\n",
    "# venue.categories looks messy from the previous result. This is why you apply \"get_category_type\"\n",
    "#   to that column, then you get the cleaned name. Of course, the function's design comes after\n",
    "#   checking the data structure in \"venues\".\n",
    "nearby_venues['venue.categories'] = nearby_venues.apply(get_category_type, axis=1)\n",
    "\n",
    "# Remove the \"venues.\" string from the column names\n",
    "nearby_venues.columns = [col.split(\".\")[-1] for col in nearby_venues.columns]\n",
    "\n",
    "# Check the result\n",
    "print('{} venues were returned by Foursquare in {}.'.format(nearby_venues.shape[0],myneigh))\n",
    "nearby_venues.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>3.1 Exploring the full zone</h4>\n",
    "Now that it has been done for one neighborhood, it can be taken to explore the full set of neghborhoods in the selected region of Toronto."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function will do the previous steps with a list of neighborhoods, provided the names and coordinates for each one (and maybe the radius to look for around the location and the limit of venues to search)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getNearbyVenues(names, latitudes, longitudes, radius=500, LIMIT=100):\n",
    "    \n",
    "    venues_list=[]\n",
    "    for name, lat, lng in zip(names, latitudes, longitudes):\n",
    "        print('Searching for venues in ',name,'...')\n",
    "            \n",
    "        # Create URL for API request\n",
    "        url = 'https://api.foursquare.com/v2/venues/explore?&client_id={}&client_secret={}&v={}&ll={},{}&radius={}&limit={}'.format(\n",
    "            CLIENT_ID, \n",
    "            CLIENT_SECRET, \n",
    "            VERSION, \n",
    "            lat, \n",
    "            lng, \n",
    "            radius, \n",
    "            LIMIT)\n",
    "            \n",
    "        # Make GET request, directly retrieving only the interesting part\n",
    "        results = requests.get(url).json()[\"response\"]['groups'][0]['items']\n",
    "        \n",
    "        # Return only relevant information for each nearby venue\n",
    "        venues_list.append([(\n",
    "            name, \n",
    "            lat, \n",
    "            lng, \n",
    "            v['venue']['name'], \n",
    "            v['venue']['location']['lat'], \n",
    "            v['venue']['location']['lng'],  \n",
    "            v['venue']['categories'][0]['name']) for v in results]) # This is a \"list comprehension\"\n",
    "        # In this type of list, you include an implicit for, which can be useful to reduce the number of lines\n",
    "        #   in a code. In this case, it looks in the \"results\" data for the specific elements and values of the\n",
    "        #   previously defined lists.\n",
    "\n",
    "    # Transform result in dataframe\n",
    "    nearby_venues = pd.DataFrame([item for venue_list in venues_list for item in venue_list]) # Nested list comprehension\n",
    "    nearby_venues.columns = ['Neighborhood', \n",
    "                  'Neighborhood Latitude', \n",
    "                  'Neighborhood Longitude', \n",
    "                  'Venue', \n",
    "                  'Venue Latitude', \n",
    "                  'Venue Longitude', \n",
    "                  'Venue Category']\n",
    "    \n",
    "    print()\n",
    "    print('Done!!',end='\\n\\n')\n",
    "    print('Returned a dataframe with shape ',nearby_venues.shape)\n",
    "    return(nearby_venues)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, apply the function to the full set of neighborhoods in Toronto:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toronto_venues = getNearbyVenues(names=justtoronto_df['Neighborhood'],\n",
    "                                   latitudes=justtoronto_df['Latitude'],\n",
    "                                   longitudes=justtoronto_df['Longitude']\n",
    "                                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toronto_venues.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many venues does each neighborhood has?\n",
    "print('Number of venues retrieved per neighborhood (dataframe):')\n",
    "toronto_venues.groupby('Neighborhood').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that the number of venues returned by Foursquare here matches the one in your \"one neighborhood\" analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many type of venues are there in this dataframe?\n",
    "print('There are {} uniques categories of venues in the dataframe.'.format(len(toronto_venues['Venue Category'].unique())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>3.2 Managing the information</h4>\n",
    "The following code will create a dataframe that show how many venues of a given type exists in each neighborhood. The dataframe will be large but this is the preparation step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One hot encoding\n",
    "# Create a dummy dataframe with columns after (unique) values in 'Venue Category'\n",
    "toronto_onehot = pd.get_dummies(toronto_venues[['Venue Category']], prefix=\"\", prefix_sep=\"\")\n",
    "\n",
    "# Add neighborhood column back to dataframe\n",
    "# With this you just create a 'Neighborhood' column in toronto_onehot\n",
    "#   with the info from toronto_venues['Neighborhood']\n",
    "toronto_onehot['Neighborhood'] = toronto_venues['Neighborhood'] \n",
    "\n",
    "# Move neighborhood column to the first column\n",
    "# The previous code results in an alphabetical order in the columns (left-to-right)\n",
    "#   thus let's move the 'Neighborhood' column to the beginning.\n",
    "colind = toronto_onehot.columns.get_loc(\"Neighborhood\") # Getting the position of column in dataframe\n",
    "fixed_columns = [toronto_onehot.columns[colind]] + list(toronto_onehot.columns[0:colind]) + list(toronto_onehot.columns[colind+1:])\n",
    "toronto_onehot = toronto_onehot[fixed_columns]\n",
    "\n",
    "### Warning! In the lab exercise, the 'Neighborhood' column was added at the end of\n",
    "###   the dataframe. That is why there you see a '-1' index to refer to that column.\n",
    "###       fixed_columns = [toronto_onehot.columns[-1]] + list(toronto_onehot.columns[:-1])\n",
    "###       toronto_onehot = toronto_onehot[fixed_columns]\n",
    "###   While checking here, I realized the alphabetical order (don't know why!).\n",
    "###   Thus, I had to modify the code to look for the column by name.\n",
    "\n",
    "toronto_onehot.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The previous dataframe establishes the occurrence of a given venue in a particular neighborhood. Let's group the occurrence of each type (category) of venue per neighborhood, making a <code>mean</code> out of the location to have an idea of the frequency of such occurrence per neighborhood. This is, of the total of venues in a given neighborhood, how feasible is to find a given type of venue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toronto_grouped = toronto_onehot.groupby('Neighborhood').mean().reset_index()\n",
    "toronto_grouped.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see in the previous results, it is more feasible to find a coffee shop than an art gallery in Berczy Park. This is more easily seen if you print the top 5 venues (according to frequency) for each neighborhood."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_top_venues = 5\n",
    "\n",
    "for hood in toronto_grouped['Neighborhood']:\n",
    "    print(\"----\" + hood + \"----\") # \"plus\" signs do not work if you mix strings and numbers!\n",
    "    # T is for Transposed. It gets the venue categories to the index side.\n",
    "    temp = toronto_grouped[toronto_grouped['Neighborhood'] == hood].T.reset_index()\n",
    "    temp.columns = ['venue','freq']\n",
    "    temp = temp.iloc[1:]\n",
    "    temp['freq'] = temp['freq'].astype(float)\n",
    "    temp = temp.round({'freq': 3})\n",
    "    print(temp.sort_values('freq', ascending=False).reset_index(drop=True).head(num_top_venues))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Note</b>: Remember that this <i>frequency</i> analysis depends on the number of venues in the neighborhood. If you see very small numbers in the top 5, it may mean there is a lot of venues in the neighborhood."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get this information into a dataframe, it is easier to create a function to return the top venues in a . The next cell will create the dataframe in a readable way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_most_common_venues(row, num_top_venues):\n",
    "    row_categories = row.iloc[1:]\n",
    "    row_categories_sorted = row_categories.sort_values(ascending=False)\n",
    "    \n",
    "    return row_categories_sorted.index.values[0:num_top_venues]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_top_venues = 10\n",
    "\n",
    "indicators = ['st', 'nd', 'rd'] # Not needed if you use \"Venue #X\" for X = 1 to num_top_venues\n",
    "\n",
    "# Create columns according to number of top venues\n",
    "columns = ['Neighborhood']\n",
    "for ind in np.arange(num_top_venues):\n",
    "    try:\n",
    "        columns.append('{}{} Most Common Venue'.format(ind+1, indicators[ind])) # Indicators for 1, 2 and 3\n",
    "    except:\n",
    "        columns.append('{}th Most Common Venue'.format(ind+1)) # When you run out of \"indicators\"\n",
    "\n",
    "# Create a new dataframe\n",
    "neighborhoods_venues_sorted = pd.DataFrame(columns=columns) # As wide as num_top_venues + 1\n",
    "neighborhoods_venues_sorted['Neighborhood'] = toronto_grouped['Neighborhood'] # Copy neighborhoods from dataframe\n",
    "\n",
    "for ind in np.arange(toronto_grouped.shape[0]): # For the number of neighborhoods in the dataframe...\n",
    "    # The function returns the first \"num_top_venues\" from the ordered list from each row\n",
    "    neighborhoods_venues_sorted.iloc[ind, 1:] = return_most_common_venues(toronto_grouped.iloc[ind, :], num_top_venues)\n",
    "\n",
    "neighborhoods_venues_sorted.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>4.1 Clustering neighborhoods using <i>K means</i></h4>\n",
    "The following code runs the <code>K means</code> model on several values for number of clusters and random-number-generator seeds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toronto_grouped_clustering = toronto_grouped.drop('Neighborhood', 1)\n",
    "for kclusters in range(3,6):\n",
    "    print()\n",
    "    print('Results for K-means with k = ',kclusters)\n",
    "    for seed in range(0,5):\n",
    "        # Execute k-means clustering for given conditions\n",
    "        kmeans = KMeans(n_clusters=kclusters, random_state=seed, n_init=12).fit(toronto_grouped_clustering)    \n",
    "        # Check cluster labels generated for each row in the dataframe\n",
    "        print('For k = {} and seed = {} the labels are: \\n {}'.format(kclusters,seed,kmeans.labels_[0:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The value of the <code>seed</code> for the random number generator that initializes the centroids of the clusters seems to influence more for lower <code>kcluster</code> values. With <code>kclusters=5</code> the results are the same. Let's use those values for the clustering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toronto_grouped_clustering = toronto_grouped.drop('Neighborhood', 1)\n",
    "kmeans = KMeans(n_clusters=5, random_state=0, n_init=12).fit(toronto_grouped_clustering)\n",
    "kmeans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's complete the dataframe for Toronto neighborhoods with the data from the neighborhoods, cluster label and top venues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add clustering labels to the sorted neighborhood venues\n",
    "neighborhoods_venues_sorted.insert(0, 'Cluster Labels', kmeans.labels_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recover the original dataframe (in this case, \"justtoronto_df\")\n",
    "toronto_merged = justtoronto_df\n",
    "\n",
    "# Add neighborhoods_venues_sorted to toronto_merged according to the neighborhood name\n",
    "toronto_merged = toronto_merged.join(neighborhoods_venues_sorted.set_index('Neighborhood'), on='Neighborhood')\n",
    "\n",
    "toronto_merged.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the final presentation, a map with colored markers for each cluster is shown as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting Toronto's coordinates\n",
    "address = 'Toronto, Ontario'\n",
    "geolocator = Nominatim(user_agent=\"TO_explorer\")\n",
    "location = geolocator.geocode(address)\n",
    "latitude = location.latitude\n",
    "longitude = location.longitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create map object\n",
    "map_clusters = folium.Map(location=[latitude, longitude], zoom_start=11)\n",
    "\n",
    "# Set color scheme for each cluster\n",
    "x = np.arange(kclusters)\n",
    "ys = [i + x + (i*x)**2 for i in range(kclusters)]\n",
    "colors_array = cm.gnuplot(np.linspace(0, 1, len(ys))) # Look for color maps in matplotlib\n",
    "rainbow = [colors.rgb2hex(i) for i in colors_array]\n",
    "\n",
    "# Add markers to the map\n",
    "markers_colors = []\n",
    "for lat, lon, hood, cluster in zip(toronto_merged['Latitude'], toronto_merged['Longitude'],\n",
    "                                  toronto_merged['Neighborhood'], toronto_merged['Cluster Labels']):\n",
    "    label = folium.Popup(str(hood) + ' (in Cluster ' + str(cluster) + ')', parse_html=True)\n",
    "    folium.CircleMarker(\n",
    "        [lat, lon],\n",
    "        radius=5,\n",
    "        popup=label,\n",
    "        color=rainbow[cluster-1],\n",
    "        fill=True,\n",
    "        fill_color=rainbow[cluster-1],\n",
    "        fill_opacity=0.7).add_to(map_clusters)\n",
    "       \n",
    "map_clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>4.2 Examining clusters</h4>\n",
    "Why that many neighborhoods are in a specific cluster? Let's see the top venues in each cluster and compare between them. Since cluster 3 is the more populated, let's check that one first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mycluster = 0\n",
    "toronto_merged.loc[toronto_merged['Cluster Labels'] == mycluster, toronto_merged.columns[[2] + list(range(5, toronto_merged.shape[1]))]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>NOTE</b>: If you run this notebook again, the \"big\" cluster can get another label. In this example, it came to be 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For cluster 0, coffee shops and cafés are the common venues on the top list. What happens with neighborhoods like \"Dufferin, Dovercourt Village\" (index 9)? It does not seem very similar. It shares bakery and bar on his top venues with a couple of other neighborhoods but it seems rather odd. Maybe the analysis tends to load the separation on the top venues rather than the whole set. Anyway, remember we are looking at the top venues here, not at every one of them. For the rest of the clusters, the comparison is straightforward:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mycluster = 1\n",
    "toronto_merged.loc[toronto_merged['Cluster Labels'] == mycluster, toronto_merged.columns[[2] + list(range(5, toronto_merged.shape[1]))]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mycluster = 2\n",
    "toronto_merged.loc[toronto_merged['Cluster Labels'] == mycluster, toronto_merged.columns[[2] + list(range(5, toronto_merged.shape[1]))]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mycluster = 3\n",
    "toronto_merged.loc[toronto_merged['Cluster Labels'] == mycluster, toronto_merged.columns[[2] + list(range(5, toronto_merged.shape[1]))]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mycluster = 4\n",
    "toronto_merged.loc[toronto_merged['Cluster Labels'] == mycluster, toronto_merged.columns[[2] + list(range(5, toronto_merged.shape[1]))]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the clusters with more than one element, top venues are very similar. There, the clustering makes sense. It may be a challenge to further analyze the data in order to see why the clustering puts that many neighborhoods in one of them (remember the results for <code>kclusters</code> from 3 to 4 in the beginning of section 4.1). Some straightforward ideas on this can be found <a href=\"https://zerowithdot.com/mistakes-with-k-means-clustering/\">here</a> and some solutions are suggested <a href=\"https://www.datanovia.com/en/lessons/determining-the-optimal-number-of-clusters-3-must-know-methods/\">here</a>. Since this is a high-dimensionality problem, the suggestion I have is to try several clusters and check the label distribution. Just set <code>maxclusters</code> in the following cell and see what's a good candidate! After that, rinse and repeat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toronto_grouped_clustering = toronto_grouped.drop('Neighborhood', 1)\n",
    "maxclusters = 10\n",
    "seed = 0\n",
    "save_k = 10\n",
    "for kclusters in range(3,maxclusters+1):\n",
    "    print()\n",
    "    print('Results for K-means with k = ',kclusters)\n",
    "    # Execute k-means clustering for given conditions\n",
    "    tmp = KMeans(n_clusters=kclusters, random_state=seed, n_init=12).fit(toronto_grouped_clustering)    \n",
    "    # Check cluster labels generated for each row in the dataframe\n",
    "    print('For k = {} and seed = {} the labels are: \\n {}'.format(kclusters,seed,tmp.labels_[0:]))\n",
    "    if kclusters == save_k:\n",
    "        kmeans = tmp\n",
    "print()\n",
    "print('Saved results for kclusters = ',save_k,' in \"kmeans\"')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
